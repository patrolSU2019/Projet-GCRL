{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LZXcFYSBs550",
        "hMJF8ZpbyLt0",
        "1WTM15ZG3QcF",
        "kNMqVXUxg9pQ",
        "Ndj4MZ4-hARb",
        "B85LDE9lhEVj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations/Préparations"
      ],
      "metadata": {
        "id": "pVXOYNmls5Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install"
      ],
      "metadata": {
        "id": "LZXcFYSBs550"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMZrJSJHsd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "outputId": "40067dae-5452-4961-b439-80d72aed099f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting importlib-metadata==4.13.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata==4.13.0) (3.15.0)\n",
            "Installing collected packages: importlib-metadata\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 6.1.0\n",
            "    Uninstalling importlib-metadata-6.1.0:\n",
            "      Successfully uninstalled importlib-metadata-6.1.0\n",
            "Successfully installed importlib-metadata-4.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/osigaud/bbrl\n",
            "  Cloning https://github.com/osigaud/bbrl to /tmp/pip-req-build-3c5jsl2z\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/osigaud/bbrl /tmp/pip-req-build-3c5jsl2z\n",
            "  Resolved https://github.com/osigaud/bbrl to commit cb2c22b82bfedfb04d8232ba432cdbd798fd797a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: bbrl\n",
            "  Building wheel for bbrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bbrl: filename=bbrl-0.1.10.dev4+gcb2c22b-py3-none-any.whl size=55867 sha256=2cc471ce2011e429507d1abb729280a4cdc6dfbdc625c2bac2ab8ce70aa42f81\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6jygvf7i/wheels/36/90/b2/6699f093f5054006fa568447050d45939efe7045bf0c569e04\n",
            "Successfully built bbrl\n",
            "Installing collected packages: bbrl\n",
            "Successfully installed bbrl-0.1.10.dev4+gcb2c22b\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=8527d1dff7333de0ff1deee241b4d6136969f9557279234ccf6d229a327db504\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install importlib-metadata==4.13.0\n",
        "#!pip install setuptools==65.5.0\n",
        "#!pip install git+https://github.com/osigaud/bbrl_gym\n",
        "!pip install git+https://github.com/osigaud/bbrl\n",
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "hMJF8ZpbyLt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bbrl.workspace import Workspace\n",
        "from bbrl import get_class, get_arguments, instantiate_class\n",
        "\n",
        "#import bbrl_gym\n",
        "import gym\n",
        "\n",
        "from bbrl.agents.agent import Agent\n",
        "from bbrl.agents import Agents, TemporalAgent, PrintAgent\n",
        "from bbrl.agents.gymb import NoAutoResetGymAgent\n",
        "\n",
        "from bbrl.utils.replay_buffer import ReplayBuffer\n",
        "from bbrl.utils.chrono import Chrono\n",
        "\n",
        "from bbrl.visu.visu_policies import plot_policy\n",
        "from bbrl.visu.visu_critics import plot_critic\n",
        "from bbrl.visu.common import final_show\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import os\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import copy"
      ],
      "metadata": {
        "id": "P5EkdUXfslay"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "j62FTCRNyOhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentés tels quels"
      ],
      "metadata": {
        "id": "1WTM15ZG3QcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "    def __init__(self, cfg):\n",
        "        self.logger = instantiate_class(cfg.logger)\n",
        "\n",
        "    def add_log(self, log_string, loss, epoch):\n",
        "        self.logger.add_scalar(log_string, loss.item(), epoch)\n",
        "\n",
        "    # Log losses\n",
        "    def log_losses(self, epoch, critic_loss, entropy_loss, actor_loss):\n",
        "        self.add_log(\"critic_loss\", critic_loss, epoch)\n",
        "        self.add_log(\"entropy_loss\", entropy_loss, epoch)\n",
        "        self.add_log(\"actor_loss\", actor_loss, epoch)\n",
        "\n",
        "    def log_reward_losses(self, rewards, nb_steps):\n",
        "        self.add_log(\"reward/mean\", rewards.mean(), nb_steps)\n",
        "        self.add_log(\"reward/max\", rewards.max(), nb_steps)\n",
        "        self.add_log(\"reward/min\", rewards.min(), nb_steps)\n",
        "        self.add_log(\"reward/median\", rewards.median(), nb_steps)\n",
        "\n",
        "def format_num(num, pos):\n",
        "    # Pos is a required parameter, but it is not used\n",
        "    magnitude = 0\n",
        "    labels = [\"\", \"K\", \"M\", \"G\"]\n",
        "    while abs(num) >= 1e3:\n",
        "        magnitude += 1\n",
        "        num /= 1e3\n",
        "\n",
        "    return f\"{num:.1f}{labels[magnitude]}\"\n",
        "\n",
        "class Plotter:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def plot_reward(\n",
        "        self,\n",
        "        algo_name,\n",
        "        env_name,\n",
        "        mode=\"mean\",\n",
        "        prefix=\"\",\n",
        "        suffix=\".pdf\",\n",
        "        save_fig=True,\n",
        "        save_dir=\"./plots/\",\n",
        "    ):\n",
        "        _, ax = plt.subplots(figsize=(9, 6))\n",
        "        formatter = FuncFormatter(format_num)\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        color = colors[0]\n",
        "\n",
        "        loader = RewardLoader(self.steps_filename, self.rewards_filename)\n",
        "        steps, rewards = loader.load()\n",
        "        print(steps, rewards)\n",
        "        # steps, rewards = equalize_lengths(steps, rewards)\n",
        "\n",
        "        if mode == \"best\":\n",
        "            best = rewards.sum(axis=1).argmax()\n",
        "            mean = rewards[best]\n",
        "        elif mode == \"max\":\n",
        "            mean = np.max(rewards, axis=0)\n",
        "        else:\n",
        "            std = rewards.std(axis=0)\n",
        "            mean = rewards.mean(axis=0)\n",
        "            ax.fill_between(steps, mean + std, mean - std, alpha=0.1, color=color)\n",
        "        ax.plot(steps, mean, lw=2, label=f\"{algo_name}\", color=color)\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "        plt.legend()\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        figure_name = f\"{prefix}{clean_env_name.lower()}_{mode}\"\n",
        "        title = f\"{clean_env_name} ({mode})\"\n",
        "        if suffix:\n",
        "            figure_name += f\"{suffix}\"\n",
        "        final_show(save_fig, True, save_dir, figure_name, \"timesteps\", \"rewards\", title)\n",
        "\n",
        "    def plot_histograms(\n",
        "        self,\n",
        "        rewards,\n",
        "        env_name,\n",
        "        suffix=\"\",\n",
        "        save_dir=\"./plots/\",\n",
        "        plot=True,\n",
        "        save_fig=True,\n",
        "    ):\n",
        "        plt.figure(figsize=(9, 6))\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        # colors = [\"#fc4f30\", \"#008fd5\", \"#e5ae38\"]\n",
        "\n",
        "        n_bars = len(rewards)\n",
        "        x = np.arange(len(list(rewards.values())[0]))\n",
        "        width = 0.75 / n_bars\n",
        "\n",
        "        for i, reward in enumerate(rewards.values()):\n",
        "            plt.bar(x + width * i, np.sort(reward)[::-1], width=width, color=colors[i])\n",
        "\n",
        "        plt.legend(labels=rewards.keys())\n",
        "        plt.xticks([], [])\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        title = clean_env_name\n",
        "        figure_name = f\"{clean_env_name.lower()}-histograms\"\n",
        "\n",
        "        if suffix:\n",
        "            title += f\" ({suffix})\"\n",
        "            figure_name += f\"{suffix}\"\n",
        "\n",
        "        final_show(save_fig, plot, save_dir, figure_name, \"\", \"rewards\", title)\n",
        "\n",
        "class RewardLogger:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "        self.episode = 0\n",
        "        self.all_rewards = []\n",
        "        self.all_rewards.append([])\n",
        "        self.all_steps = []\n",
        "\n",
        "    def add(self, nb_steps, reward):\n",
        "        if self.episode == 0:\n",
        "            self.all_steps.append(nb_steps)\n",
        "        self.all_rewards[self.episode].append(reward.item())\n",
        "\n",
        "    def new_episode(self):\n",
        "        self.episode += 1\n",
        "        self.all_rewards.append([])\n",
        "\n",
        "    def save(self):\n",
        "        # print(\"reward loader save:\", self.all_steps,  self.all_rewards)\n",
        "        with open(self.steps_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_steps)\n",
        "        with open(self.rewards_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_rewards)\n",
        "\n",
        "class RewardLoader:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def load(self):\n",
        "        with open(self.steps_filename, \"rb\") as f:\n",
        "            steps = np.load(f, allow_pickle=True)\n",
        "        with open(self.rewards_filename, \"rb\") as f:\n",
        "            rewards = np.load(f, allow_pickle=True)\n",
        "        return steps, rewards"
      ],
      "metadata": {
        "id": "Uvi68vi0aE7d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(sizes, activation, output_activation=nn.Identity()):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        act = activation if j < len(sizes) - 2 else output_activation\n",
        "        layers += [nn.Linear(sizes[j], sizes[j + 1]), act]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def build_alt_mlp(sizes, activation):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        if j < len(sizes) - 2:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1]), activation]\n",
        "        else:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1])]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class DiscreteQAgent(Agent):\n",
        "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
        "        super().__init__()\n",
        "        self.is_q_function = True\n",
        "        self.model = build_alt_mlp(\n",
        "            [state_dim] + list(hidden_layers) + [action_dim], activation=nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, t, choose_action=True, **kwargs):\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        self.set((\"q_values\", t), q_values)\n",
        "        if choose_action:\n",
        "            action = q_values.argmax(-1)\n",
        "            self.set((\"action\", t), action)\n",
        "\n",
        "    def predict_action(self, obs, stochastic):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        if stochastic:\n",
        "            probs = torch.softmax(q_values, dim=-1)\n",
        "            action = torch.distributions.Categorical(probs).sample()\n",
        "        else:\n",
        "            action = q_values.argmax(-1)\n",
        "        return action\n",
        "\n",
        "    def predict_value(self, obs, action):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        return q_values[action[0].int()]\n",
        "\n",
        "\n",
        "class ContinuousQAgent(Agent):\n",
        "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
        "        super().__init__()\n",
        "        self.is_q_function = True\n",
        "        self.model = build_mlp(\n",
        "            [state_dim + action_dim] + list(hidden_layers) + [1], activation=nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, t, detach_actions=False):\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        action = self.get((\"action\", t))\n",
        "        if detach_actions:\n",
        "            action = action.detach()\n",
        "        osb_act = torch.cat((obs, action), dim=1)\n",
        "        q_value = self.model(osb_act)\n",
        "        self.set((\"q_value\", t), q_value)\n",
        "\n",
        "    def predict_value(self, obs, action):\n",
        "        obs_act = torch.cat((obs, action), dim=0)\n",
        "        q_value = self.model(obs_act)\n",
        "        return q_value\n",
        "\n",
        "\n",
        "def make_gym_env(env_name):\n",
        "    return gym.make(env_name)\n",
        "\n",
        "\n",
        "class EGreedyActionSelector(Agent):\n",
        "    def __init__(self, epsilon):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        q_values = self.get((\"q_values\", t))\n",
        "        nb_actions = q_values.size()[1]\n",
        "        size = q_values.size()[0]\n",
        "        is_random = torch.rand(size).lt(self.epsilon).float()\n",
        "        random_action = torch.randint(low=0, high=nb_actions, size=(size,))\n",
        "        max_action = q_values.max(1)[1]\n",
        "        action = is_random * random_action + (1 - is_random) * max_action\n",
        "        action = action.long()\n",
        "        self.set((\"action\", t), action)"
      ],
      "metadata": {
        "id": "qV_L1P7H2ZdY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentés par nous"
      ],
      "metadata": {
        "id": "ppvuEIU13vFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CartWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(CartWrapper, self).__init__(env)\n",
        "\n",
        "        # choix arbitraire d'un goal de départ\n",
        "        pos = random.uniform(-2.4, 2.4)\n",
        "        vel = random.uniform(-1e8, 1e8)\n",
        "        angle = random.uniform(-.2095, .2095)\n",
        "        angle_vel = random.uniform(-1e8, 1e8)\n",
        "        self.goal = (pos, vel, angle, angle_vel)\n",
        "\n",
        "        # distance acceptable autour du but\n",
        "        self.eps = 0.01\n",
        "\n",
        "    def step(self, action):\n",
        "        # effectue un step de l'env CartPole\n",
        "        next_state, _, _, info = self.env.step(action)\n",
        "\n",
        "        # calcul de distance entre next_state et le but\n",
        "        distance = np.linalg.norm(next_state - self.goal)\n",
        "\n",
        "        # récompense et fin si distance inférieure à eps\n",
        "        if distance < self.eps:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return next_state, reward, done, info\n",
        "\n",
        "\n",
        "class GoalRelabellingAgent(Agent):\n",
        "    def __init__(self, env: CartWrapper):\n",
        "        super().__init__()\n",
        "        self.env = env # ?\n",
        "\n",
        "    def change_goal(self):\n",
        "        # modification du but\n",
        "        new_goal = self.choice_goal()\n",
        "        self.env.goal = new_goal\n",
        "        # TO-DO\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "PpPmz_8R97pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "1v6XjQd9zKmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARAMS"
      ],
      "metadata": {
        "id": "kNMqVXUxg9pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params={\n",
        "  \"save_best\": False,\n",
        "  \"plot_agents\": True,\n",
        "  \n",
        "  \"logger\":{\n",
        "    \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
        "    \"log_dir\": \"./dqn_logs/\",\n",
        "    \"cache_size\": 10000,\n",
        "    \"every_n_seconds\": 1,\n",
        "    \"verbose\": False,    \n",
        "  },\n",
        "\n",
        "  \"algorithm\":{\n",
        "    \"seed\": 0,                      # modifié par la main loop\n",
        "    \"nb_seeds\": 10,                  # nb de seed testées (de 0 à valeur proposée)\n",
        "\n",
        "    \"epsilon\": 0.05,                 # valeur pour epsilon-greedy\n",
        "    \"discount_factor\": 0.99,        # delta\n",
        "    \"gae\": 0.8,                     # ???\n",
        "\n",
        "    \"n_steps\": 64,                  # nb max de step par épisode ?\n",
        "    \"n_envs\": 10,                    # nb d'environnement en simultané\n",
        "    \"n_episodes\": 20,                # nb d'épisodes\n",
        "    \"nb_evals\": 5,                 # nb d'évaluation après train\n",
        "    \"eval_interval\": 10,            # intervalle (steps) entre évaluations ?\n",
        "    \"target_critic_update\": 10,    # intervalle (steps) entre chaque maj de Q_target ?\n",
        "\n",
        "    \"learning_starts\": 1,           # ???\n",
        "\n",
        "    \"n_updates\": 20,                # nb d'update par le Replay Buffer\n",
        "    \"buffer_size\": 1e6,             # taille max du Replay Buffer\n",
        "    \"batch_size\": 50,              # taille du batch Replay Buffer\n",
        "\n",
        "    \"max_grad_norm\": 0.5,           # ???\n",
        "    \"architecture\":{\"hidden_size\": [128, 128]},\n",
        "  },\n",
        "\n",
        "  \"gym_env\":{\n",
        "    \"classname\": \"__main__.make_gym_env\",\n",
        "    \"env_name\": \"CartPole-v1\"\n",
        "  },\n",
        "\n",
        "  \"optimizer\":{\n",
        "    \"classname\": \"torch.optim.Adam\",\n",
        "    \"lr\": 2.3e-3,\n",
        "  }\n",
        "}\n",
        "\n",
        "config = OmegaConf.create(params)"
      ],
      "metadata": {
        "id": "wyiQEOfXzLz7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET-UP"
      ],
      "metadata": {
        "id": "Ndj4MZ4-hARb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_env_agents(cfg):\n",
        "    train_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.n_envs,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    # print_agent = PrintAgent()\n",
        "    eval_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.nb_evals,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    return train_env_agent, eval_env_agent\n",
        "\n",
        "\n",
        "def create_dqn_agent(cfg, train_env_agent, eval_env_agent):\n",
        "    obs_size, act_size = train_env_agent.get_obs_and_actions_sizes()\n",
        "\n",
        "    critic = DiscreteQAgent(obs_size, cfg.algorithm.architecture.hidden_size, act_size)\n",
        "    explorer = EGreedyActionSelector(cfg.algorithm.epsilon)\n",
        "    target_critic = copy.deepcopy(critic)\n",
        "\n",
        "    q_agent = TemporalAgent(critic)\n",
        "    target_q_agent = TemporalAgent(target_critic)\n",
        "    \n",
        "    tr_agent = Agents(train_env_agent, critic, explorer)\n",
        "    ev_agent = Agents(eval_env_agent, critic)\n",
        "    # Get an agent that is executed on a complete workspace\n",
        "    train_agent = TemporalAgent(tr_agent)\n",
        "    eval_agent = TemporalAgent(ev_agent)\n",
        "    \n",
        "    train_agent.seed(cfg.algorithm.seed)\n",
        "    return train_agent, eval_agent, q_agent, target_q_agent\n",
        "\n",
        "\n",
        "# Configure the optimizer\n",
        "def setup_optimizers(cfg, q_agent):\n",
        "    optimizer_args = get_arguments(cfg.optimizer)\n",
        "    parameters = q_agent.parameters()\n",
        "    optimizer = get_class(cfg.optimizer)(parameters, **optimizer_args)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def compute_critic_loss(cfg, reward, must_bootstrap, q_values, target_q_values, action):\n",
        "    # Compute temporal difference\n",
        "    max_q = target_q_values[1].max(-1)[0].detach()\n",
        "\n",
        "    target = (\n",
        "        reward[:-1]\n",
        "        + cfg.algorithm.discount_factor * max_q * must_bootstrap.int()\n",
        "    )\n",
        "\n",
        "    vals = q_values.squeeze()\n",
        "    qvals = torch.gather(vals, dim=1, index=action)\n",
        "    qvals = qvals[:-1]\n",
        "\n",
        "    mse = nn.MSELoss()\n",
        "    critic_loss = mse(target, qvals)\n",
        "    return critic_loss"
      ],
      "metadata": {
        "id": "HauPdovyH5fG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN"
      ],
      "metadata": {
        "id": "B85LDE9lhEVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dqn(cfg, reward_logger):\n",
        "    # 1)  Build the  logger\n",
        "    logger = Logger(cfg)\n",
        "    best_reward = -10e9\n",
        "\n",
        "    # 2) Create the environment agent\n",
        "    train_env_agent, eval_env_agent = get_env_agents(cfg)\n",
        "\n",
        "    # 3) Create the DQN-like Agent\n",
        "    train_agent, eval_agent, q_agent, target_q_agent = create_dqn_agent(cfg, train_env_agent, eval_env_agent)\n",
        "\n",
        "    # Used for training\n",
        "    train_workspace = Workspace()\n",
        "\n",
        "    # 4) Create the Replay Buffer Agent\n",
        "    rb = ReplayBuffer(max_size=cfg.algorithm.buffer_size)\n",
        "\n",
        "    # 5) Create the HER Agent\n",
        "    # TO-DO\n",
        "\n",
        "    # 6) Configure the optimizer\n",
        "    optimizer = setup_optimizers(cfg, q_agent)\n",
        "    nb_steps = 0\n",
        "    tmp_steps = 0\n",
        "    tmp_steps2 = 0\n",
        "\n",
        "    # 7) Training\n",
        "    # Train des épisodes        \n",
        "    train_agent(train_workspace, t=0, stop_variable=\"env/done\", stochastic=True)\n",
        "\n",
        "    transition_workspace = train_workspace.get_transitions()\n",
        "\n",
        "    # comptage du nb de step de l'épisode\n",
        "    action = transition_workspace[\"action\"]\n",
        "    nb_steps += action[0].shape[0]\n",
        "\n",
        "    # ajout des transitions au RB\n",
        "    rb.put(transition_workspace)\n",
        "\n",
        "    # 7.1) Loop Replay Buffer\n",
        "    for _ in range(cfg.algorithm.n_updates):\n",
        "        # mélange et création du RB_W\n",
        "        rb_workspace = rb.get_shuffled(cfg.algorithm.batch_size)\n",
        "\n",
        "        # The q agent needs to be executed on the rb_workspace workspace (gradients are removed in workspace).\n",
        "        q_agent(rb_workspace, t=0, n_steps=2, choose_action=False)\n",
        "\n",
        "        q_values, done, truncated, reward, action = rb_workspace[\n",
        "            \"q_values\", \"env/done\", \"env/truncated\", \"env/reward\", \"action\"\n",
        "        ]\n",
        "\n",
        "        # print\n",
        "        #print(\"q_values:\", q_values)\n",
        "        #print(\"done:\", done)\n",
        "        #print(\"truncated:\", truncated)\n",
        "        #print(\"reward:\", reward)\n",
        "        #print(\"action:\", action)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_q_agent(rb_workspace, t=0, n_steps=2, stochastic=True)\n",
        "\n",
        "        target_q_values = rb_workspace[\"q_values\"]\n",
        "        # assert torch.equal(q_values, target_q_values), \"values differ\"\n",
        "\n",
        "        # Determines whether values of the critic should be propagated\n",
        "        # True if the episode reached a time limit or if the task was not done\n",
        "        # See https://colab.research.google.com/drive/1erLbRKvdkdDy0Zn1X_JhC01s1QAt4BBj?usp=sharing\n",
        "        must_bootstrap = torch.logical_or(~done[1], truncated[1])\n",
        "\n",
        "        if rb.size() > cfg.algorithm.learning_starts:\n",
        "            # Compute critic loss\n",
        "            critic_loss = compute_critic_loss(\n",
        "                cfg, reward, must_bootstrap, q_values[0], target_q_values[1], action\n",
        "            )\n",
        "\n",
        "            # Store the loss for tensorboard display\n",
        "            logger.add_log(\"critic_loss\", critic_loss, nb_steps)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                q_agent.parameters(), cfg.algorithm.max_grad_norm\n",
        "            )\n",
        "            optimizer.step()\n",
        "\n",
        "    # 7.2) Maj du Q_target (sous conditions)\n",
        "    if nb_steps - tmp_steps2 > cfg.algorithm.target_critic_update:\n",
        "        tmp_steps2 = nb_steps\n",
        "        target_q_agent.agent = copy.deepcopy(q_agent.agent)\n",
        "    \n",
        "    # 7.3) Évaluation régulère\n",
        "    if nb_steps - tmp_steps > cfg.algorithm.eval_interval:\n",
        "        tmp_steps = nb_steps\n",
        "        eval_workspace = Workspace()  # Used for evaluation\n",
        "        eval_agent(\n",
        "            eval_workspace, t=0, stop_variable=\"env/done\", choose_action=True\n",
        "        )\n",
        "        rewards = eval_workspace[\"env/cumulated_reward\"][-1]\n",
        "        mean = rewards.mean()\n",
        "        logger.add_log(\"reward\", mean, nb_steps)\n",
        "        print(f\"reward: {mean}\")\n",
        "        reward_logger.add(nb_steps, mean)\n",
        "        \n",
        "        if cfg.save_best and mean > best_reward:\n",
        "            best_reward = mean\n",
        "            directory = \"./dqn_critic/\"\n",
        "            \n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            \n",
        "            filename = directory + \"dqn_\" + str(mean.item()) + \".agt\"\n",
        "            eval_agent.save_model(filename)\n",
        "            \n",
        "            if cfg.plot_agents:\n",
        "                policy = eval_agent.agent.agents[1]\n",
        "                plot_policy(\n",
        "                    policy,\n",
        "                    eval_env_agent,\n",
        "                    \"./dqn_plots/\",\n",
        "                    cfg.gym_env.env_name,\n",
        "                    best_reward,\n",
        "                    stochastic=False,\n",
        "                )\n",
        "                plot_critic(\n",
        "                    policy,\n",
        "                    eval_env_agent,\n",
        "                    \"./dqn_plots/\",\n",
        "                    cfg.gym_env.env_name,\n",
        "                    best_reward,\n",
        "                )"
      ],
      "metadata": {
        "id": "ntdxI1XDR2CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dqn_2(cfg, reward_logger):\n",
        "    # 1)  Build the  logger\n",
        "    logger = Logger(cfg)\n",
        "    best_reward = -10e9\n",
        "\n",
        "    # 2) Create the environment agent\n",
        "    train_env_agent, eval_env_agent = get_env_agents(cfg)\n",
        "\n",
        "    # 3) Create the DQN-like Agent\n",
        "    train_agent, eval_agent, q_agent, target_q_agent = create_dqn_agent(cfg, train_env_agent, eval_env_agent)\n",
        "\n",
        "    # 4) Create the Replay Buffer Agent\n",
        "    rb = ReplayBuffer(max_size=cfg.algorithm.buffer_size)\n",
        "\n",
        "    # 5) Create the HER Agent\n",
        "    # TO-DO\n",
        "\n",
        "    # 6) Configure the optimizer\n",
        "    optimizer = setup_optimizers(cfg, q_agent)\n",
        "    nb_steps = 0\n",
        "    tmp_steps = 0\n",
        "    tmp_steps2 = 0\n",
        "\n",
        "    # 7) Training\n",
        "    # Train des épisodes\n",
        "    for _ in range(cfg.algorithm.n_episodes):\n",
        "        train_workspace = Workspace()\n",
        "        train_agent(train_workspace, t=0, stop_variable=\"env/done\", stochastic=True)\n",
        "\n",
        "        transition_workspace = train_workspace.get_transitions()\n",
        "\n",
        "        # comptage du nb de step de l'épisode\n",
        "        action = transition_workspace[\"action\"]\n",
        "        nb_steps += action[0].shape[0]\n",
        "\n",
        "        # ajout des transitions au RB\n",
        "        rb.put(transition_workspace)\n",
        "\n",
        "        # 7.1) Loop Replay Buffer\n",
        "        for _ in range(cfg.algorithm.n_updates):\n",
        "            # mélange et création du RB_W\n",
        "            rb_workspace = rb.get_shuffled(cfg.algorithm.batch_size)\n",
        "\n",
        "            # The q agent needs to be executed on the rb_workspace workspace (gradients are removed in workspace).\n",
        "            q_agent(rb_workspace, t=0, n_steps=2, choose_action=False)\n",
        "\n",
        "            q_values, done, truncated, reward, action = rb_workspace[\n",
        "                \"q_values\", \"env/done\", \"env/truncated\", \"env/reward\", \"action\"\n",
        "            ]\n",
        "\n",
        "            # print\n",
        "            #print(\"q_values:\", q_values)\n",
        "            #print(\"done:\", done)\n",
        "            #print(\"truncated:\", truncated)\n",
        "            #print(\"reward:\", reward)\n",
        "            #print(\"action:\", action)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                target_q_agent(rb_workspace, t=0, n_steps=2, stochastic=True)\n",
        "\n",
        "            target_q_values = rb_workspace[\"q_values\"]\n",
        "            # assert torch.equal(q_values, target_q_values), \"values differ\"\n",
        "\n",
        "            # Determines whether values of the critic should be propagated\n",
        "            # True if the episode reached a time limit or if the task was not done\n",
        "            # See https://colab.research.google.com/drive/1erLbRKvdkdDy0Zn1X_JhC01s1QAt4BBj?usp=sharing\n",
        "            must_bootstrap = torch.logical_or(~done[1], truncated[1])\n",
        "\n",
        "            if rb.size() > cfg.algorithm.learning_starts:\n",
        "                # Compute critic loss\n",
        "                critic_loss = compute_critic_loss(\n",
        "                    cfg, reward, must_bootstrap, q_values[0], target_q_values[1], action\n",
        "                )\n",
        "\n",
        "                # Store the loss for tensorboard display\n",
        "                logger.add_log(\"critic_loss\", critic_loss, nb_steps)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    q_agent.parameters(), cfg.algorithm.max_grad_norm\n",
        "                )\n",
        "                optimizer.step()\n",
        "\n",
        "        # 7.2) Maj du Q_target (sous conditions)\n",
        "        if nb_steps - tmp_steps2 > cfg.algorithm.target_critic_update:\n",
        "            tmp_steps2 = nb_steps\n",
        "            target_q_agent.agent = copy.deepcopy(q_agent.agent)\n",
        "        \n",
        "        # 7.3) Évaluation régulère\n",
        "        if nb_steps - tmp_steps > cfg.algorithm.eval_interval:\n",
        "            tmp_steps = nb_steps\n",
        "            eval_workspace = Workspace()  # Used for evaluation\n",
        "            eval_agent(\n",
        "                eval_workspace, t=0, stop_variable=\"env/done\", choose_action=True\n",
        "            )\n",
        "            rewards = eval_workspace[\"env/cumulated_reward\"][-1]\n",
        "            mean = rewards.mean()\n",
        "            logger.add_log(\"reward\", mean, nb_steps)\n",
        "            print(f\"reward: {mean}\")\n",
        "            reward_logger.add(nb_steps, mean)\n",
        "            \n",
        "            if cfg.save_best and mean > best_reward:\n",
        "                best_reward = mean\n",
        "                directory = \"./dqn_critic/\"\n",
        "                \n",
        "                if not os.path.exists(directory):\n",
        "                    os.makedirs(directory)\n",
        "                \n",
        "                filename = directory + \"dqn_\" + str(mean.item()) + \".agt\"\n",
        "                eval_agent.save_model(filename)\n",
        "                \n",
        "                if cfg.plot_agents:\n",
        "                    policy = eval_agent.agent.agents[1]\n",
        "                    plot_policy(\n",
        "                        policy,\n",
        "                        eval_env_agent,\n",
        "                        \"./dqn_plots/\",\n",
        "                        cfg.gym_env.env_name,\n",
        "                        best_reward,\n",
        "                        stochastic=False,\n",
        "                    )\n",
        "                    plot_critic(\n",
        "                        policy,\n",
        "                        eval_env_agent,\n",
        "                        \"./dqn_plots/\",\n",
        "                        cfg.gym_env.env_name,\n",
        "                        best_reward,\n",
        "                    )"
      ],
      "metadata": {
        "id": "Yi388sJMkKU1"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN"
      ],
      "metadata": {
        "id": "u18OyRDdqMBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_loop(cfg):\n",
        "    chrono = Chrono()\n",
        "    logdir = \"./plot/\"\n",
        "\n",
        "    if not os.path.exists(logdir):\n",
        "        os.makedirs(logdir)\n",
        "\n",
        "    reward_logger = RewardLogger(\n",
        "        logdir + \"dqn_test.steps\", logdir + \"dqn_test.rwd\"\n",
        "    )\n",
        "\n",
        "    for seed in range(cfg.algorithm.nb_seeds):\n",
        "        cfg.algorithm.seed = seed\n",
        "        torch.manual_seed(cfg.algorithm.seed)\n",
        "        run_dqn_2(cfg, reward_logger)\n",
        "\n",
        "        if seed < cfg.algorithm.nb_seeds - 1:\n",
        "            reward_logger.new_episode()\n",
        "\n",
        "    reward_logger.save()\n",
        "    chrono.stop()\n",
        "    plotter = Plotter(logdir + \"dqn_test.steps\", logdir + \"dqn_test.rwd\")\n",
        "    plotter.plot_reward(\"dqn_test\", cfg.gym_env.env_name)"
      ],
      "metadata": {
        "id": "GSN9tztCZX-7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loop(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jfewpf6pZgQ2",
        "outputId": "8308d94a-73e4-4758-fad8-3a56e3d46dc6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reward: 121.0\n",
            "reward: 24.799999237060547\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.800000190734863\n",
            "reward: 9.800000190734863\n",
            "reward: 8.800000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.800000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.199999809265137\n",
            "reward: 9.0\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 8.800000190734863\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 11.600000381469727\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 20.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 15.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 9.800000190734863\n",
            "reward: 8.800000190734863\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.0\n",
            "reward: 9.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 18.0\n",
            "reward: 9.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.800000190734863\n",
            "reward: 10.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 12.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 137.39999389648438\n",
            "reward: 10.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.0\n",
            "reward: 9.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 9.800000190734863\n",
            "reward: 9.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 74.80000305175781\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 14.0\n",
            "reward: 8.800000190734863\n",
            "reward: 9.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 8.800000190734863\n",
            "reward: 8.800000190734863\n",
            "reward: 11.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 12.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 18.200000762939453\n",
            "reward: 9.199999809265137\n",
            "reward: 13.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 13.800000190734863\n",
            "reward: 9.199999809265137\n",
            "reward: 146.0\n",
            "reward: 20.799999237060547\n",
            "reward: 41.79999923706055\n",
            "reward: 22.399999618530273\n",
            "reward: 52.599998474121094\n",
            "reward: 14.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 8.800000190734863\n",
            "reward: 9.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 24.0\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 19.600000381469727\n",
            "reward: 12.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 74.0\n",
            "reward: 15.0\n",
            "reward: 112.19999694824219\n",
            "reward: 8.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 34.0\n",
            "reward: 10.199999809265137\n",
            "reward: 12.600000381469727\n",
            "reward: 14.600000381469727\n",
            "reward: 12.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 14.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 17.0\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 9.800000190734863\n",
            "reward: 20.399999618530273\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.0\n",
            "reward: 10.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 9.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 13.0\n",
            "reward: 9.600000381469727\n",
            "reward: 10.0\n",
            "reward: 9.800000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 10.0\n",
            "reward: 9.399999618530273\n",
            "reward: 9.199999809265137\n",
            "reward: 19.200000762939453\n",
            "reward: 10.0\n",
            "reward: 12.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.600000381469727\n",
            "reward: 9.0\n",
            "reward: 9.399999618530273\n",
            "reward: 15.600000381469727\n",
            "reward: 11.600000381469727\n",
            "reward: 9.399999618530273\n",
            "reward: 16.799999237060547\n",
            "reward: 9.199999809265137\n",
            "reward: 9.0\n",
            "reward: 38.20000076293945\n",
            "reward: 14.0\n",
            "reward: 32.20000076293945\n",
            "reward: 16.799999237060547\n",
            "reward: 10.600000381469727\n",
            "reward: 34.400001525878906\n",
            "reward: 9.0\n",
            "reward: 9.600000381469727\n",
            "reward: 109.0\n",
            "reward: 45.400001525878906\n",
            "reward: 27.200000762939453\n",
            "reward: 9.600000381469727\n",
            "reward: 9.199999809265137\n",
            "reward: 61.20000076293945\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 15.600000381469727\n",
            "Time : 32s 193ms\n",
            "[135 203 252 303 394 443 500 550 692 745] [[13.19999981  9.30000019  9.30000019 23.39999962  9.5         9.69999981\n",
            "   9.39999962 31.10000038  9.5        54.90000153]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvwAAAIjCAYAAAB/MM91AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACCqElEQVR4nO3dd3hUZd7G8e+kTxJSSSGkAqFXQTGAUhVBsbGr64KAiwXFFQs2lFWx4OoK6ruIoogI69rWjqIiRUFApQhIx4QeQktCepnz/pFkmJEWQpIzmbk/15Vrp2XmJrPInTPP+T0WwzAMRERERETELXmZHUBEREREROqOCr+IiIiIiBtT4RcRERERcWMq/CIiIiIibkyFX0RERETEjanwi4iIiIi4MRV+ERERERE3psIvIiIiIuLGVPhFRERERNyYCr+IiJxWnz596NOnT60/7+DBg7nllltq/XnNsHHjRnx8fNiwYYPZUURETqDCLyJSi3bs2MFtt91Gs2bNCAgIICQkhJ49e/LSSy9RWFhYq6/1zDPP8Mknn5xw+1tvvYXFYrF/BQQE0LJlS+68804OHDhQqxlqatmyZXzzzTc8+OCDZkepFW3btuXyyy/nH//4h9lRRERO4GN2ABERdzFv3jz+/Oc/4+/vz4gRI2jfvj0lJSUsXbqU+++/n99++40ZM2bU2us988wz/OlPf+Lqq68+6f2TJk0iJSWFoqIili5dyvTp0/nyyy/ZsGEDgYGBtZajJp5//nn69+9PixYtTM1Rm8aMGcPgwYPZsWMHzZs3NzuOiIidCr+ISC1IT0/nL3/5C0lJSSxcuJAmTZrY7xs7dizbt29n3rx55/w6hmFQVFSE1Wo942MHDRpEt27dALj55puJjIxkypQpfPrpp9xwww3nnKWmsrKymDdvHq+++qppGerCgAEDCA8PZ/bs2UyaNMnsOCIidlrSIyJSC5577jny8vKYOXOmU9mv0qJFC8aNG2e/PmvWLPr160d0dDT+/v60bduW6dOnn/B9ycnJXHHFFXz99dd069YNq9XKa6+9hsViIT8/n9mzZ9uX7owaNeq0Gfv16wdU/HICUFZWxpNPPknz5s3x9/cnOTmZCRMmUFxcfMY/b3FxMY899hgtWrTA39+fhIQEHnjggWp977x58ygrK2PAgAFOt1ctRVq6dCl33XUXUVFRhIWFcdttt1FSUkJ2djYjRowgPDyc8PBwHnjgAQzDcHoOm83Giy++SLt27QgICCAmJobbbruNo0ePOj3u008/5fLLLycuLg5/f3+aN2/Ok08+SXl5udPj+vTpQ/v27dm4cSN9+/YlMDCQpk2b8txzz53w5/L19aVPnz58+umnZ/wZiIjUJx3hFxGpBZ9//jnNmjWjR48e1Xr89OnTadeuHVdeeSU+Pj58/vnn3HHHHdhsNsaOHev02C1btnDDDTdw2223ccstt9CqVSvmzJnDzTffzAUXXMCtt94KcMZlJDt27AAgMjISqDjqP3v2bP70pz9x3333sXLlSiZPnsymTZv4+OOPT/k8NpuNK6+8kqVLl3LrrbfSpk0b1q9fz9SpU9m6detJzytw9OOPPxIZGUlSUtJJ7//73/9ObGwsTzzxBCtWrGDGjBmEhYXx448/kpiYyDPPPMOXX37J888/T/v27RkxYoT9e2+77TbeeustbrrpJu666y7S09P597//zZo1a1i2bBm+vr5AxS8XwcHB3HvvvQQHB7Nw4UL+8Y9/kJuby/PPP++U5+jRo1x22WVce+21XHfddXz44Yc8+OCDdOjQgUGDBjk9tmvXrnz66afk5uYSEhJy2p+DiEi9MURE5Jzk5OQYgHHVVVdV+3sKCgpOuG3gwIFGs2bNnG5LSkoyAGP+/PknPD4oKMgYOXLkCbfPmjXLAIwFCxYYBw8eNHbv3m28++67RmRkpGG1Wo09e/YYa9euNQDj5ptvdvre8ePHG4CxcOFC+229e/c2evfubb8+Z84cw8vLy/jhhx+cvvfVV181AGPZsmWn/bP36tXL6Nq16ylzDxw40LDZbPbb09LSDIvFYowZM8Z+W1lZmREfH++U64cffjAA4z//+Y/T886fP/+E20/287/tttuMwMBAo6ioyOnPDhhvv/22/bbi4mIjNjbWGDp06AnP8c477xiAsXLlytP+DERE6pOW9IiInKPc3FwAGjVqVO3vcVyDn5OTw6FDh+jduze///47OTk5To9NSUlh4MCBZ51rwIABREVFkZCQwF/+8heCg4P5+OOPadq0KV9++SUA9957r9P33HfffQCnPd/ggw8+oE2bNrRu3ZpDhw7Zv6qWDC1atOi0uQ4fPkx4ePgp7x89ejQWi8V+vXv37hiGwejRo+23eXt7061bN37//XenXKGhoVxyySVOubp27UpwcLBTLsef/7Fjxzh06BAXXXQRBQUFbN682SlPcHAww4cPt1/38/PjggsucHrtKlV/rkOHDp32ZyAiUp+0pEdE5BxVLd04duxYtb9n2bJlPPbYYyxfvpyCggKn+3JycggNDbVfT0lJqVGuadOm0bJlS3x8fIiJiaFVq1Z4eVUc59m5cydeXl4nTMmJjY0lLCyMnTt3nvJ5t23bxqZNm4iKijrp/VlZWWfMZvxh7b2jxMREp+tVP4uEhIQTbndcm79t2zZycnKIjo4+Y67ffvuNRx99lIULF9p/Yavyx1+44uPjnX4BgYpiv27duhNeo+rP9cfHi4iYSYVfROQchYSEEBcXV+1Nl3bs2EH//v1p3bo1U6ZMISEhAT8/P7788kumTp2KzWZzenx1JvKczAUXXGCf0nMqNSmmNpuNDh06MGXKlJPe/8di/keRkZEnnETryNvbu9q3O/7iYLPZiI6O5j//+c9Jv7/qF5Ts7Gx69+5NSEgIkyZNonnz5gQEBLB69WoefPDBE37+p8pzsl9aqv5cjRs3Pun3iIiYQYVfRKQWXHHFFcyYMYPly5eTlpZ22sd+/vnnFBcX89lnnzkdzT7TUpg/OpejyElJSdhsNrZt20abNm3stx84cIDs7OxTnlALFScH//rrr/Tv379GGVq3bs3//ve/GuU+nebNm7NgwQJ69ux52l+SFi9ezOHDh/noo4+4+OKL7bdXTS86F+np6Xh5edGyZctzfi4RkdqiNfwiIrXggQceICgoiJtvvvmku9nu2LGDl156CTh+xNjxCHFOTg6zZs06q9cMCgoiOzu7RnkHDx4MwIsvvuh0e9VR+8svv/yU33vdddexd+9eXn/99RPuKywsJD8//7SvnZaWxtGjR0+6Bv5cXHfddZSXl/Pkk0+ecF9ZWZn9Z3Wyn39JSQmvvPLKOWdYtWoV7dq1c1qSJSJiNh3hFxGpBc2bN+edd97h+uuvp02bNk477f7444988MEH9jn5l156KX5+fgwZMoTbbruNvLw8Xn/9daKjo9m/f3+1X7Nr164sWLCAKVOmEBcXR0pKCt27d6/W93bq1ImRI0cyY8YM+xKXn376idmzZ3P11VfTt2/fU37vjTfeyPvvv8+YMWNYtGgRPXv2pLy8nM2bN/P+++/b9ww4lcsvvxwfHx8WLFhgHylaG3r37s1tt93G5MmTWbt2LZdeeim+vr5s27aNDz74gJdeeok//elP9OjRg/DwcEaOHMldd92FxWJhzpw5pz2voDpKS0tZsmQJd9xxRy39iUREaocKv4hILbnyyitZt24dzz//PJ9++inTp0/H39+fjh078sILL3DLLbcA0KpVKz788EMeffRRxo8fT2xsLLfffjtRUVH87W9/q/brTZkyhVtvvZVHH32UwsJCRo4cWe3CD/DGG2/QrFkz3nrrLT7++GNiY2N5+OGHeeyxx077fV5eXnzyySdMnTqVt99+m48//pjAwECaNWvGuHHjzricJSYmhsGDB/P+++/XauEHePXVV+natSuvvfYaEyZMwMfHh+TkZIYPH07Pnj2BinMIvvjiC+677z4effRRwsPDGT58OP3796/RNKQq3333HUeOHGHkyJG19ccREakVFuNcD2mIiIicpR9++IE+ffqwefNmUlNTzY5TK66++mosFstpNy0TETGDCr+IiJhi0KBBxMfHn/RcgIZm06ZNdOjQgbVr19K+fXuz44iIOFHhFxERERFxY5rSIyIiIiLixlT4RURERETcmAq/iIiIiIgbU+EXEREREXFjbj+H32azsW/fPho1anRO29CLiIiIiLgKwzA4duwYcXFxeHmd/hi+2xf+ffv2kZCQYHYMEREREZFat3v3buLj40/7GLcv/I0aNQIqfhghISEmpxEREREROXe5ubkkJCTYu+7puH3hr1rGExISosIvIiIiIm6lOkvWddKuiIiIiIgbU+EXEREREXFjKvwiIiIiIm7M7dfwV4dhGJSVlVFeXm52FDkDb29vfHx8NGJVREREpJo8vvCXlJSwf/9+CgoKzI4i1RQYGEiTJk3w8/MzO4qIiIiIy/Powm+z2UhPT8fb25u4uDj8/Px05NiFGYZBSUkJBw8eJD09ndTU1DNuNCEiIiLi6Ty68JeUlGCz2UhISCAwMNDsOFINVqsVX19fdu7cSUlJCQEBAWZHEhEREXFpOjwKOkrcwOj9EhEREak+NScRERERETemwi8iIiIi4sZU+N1Inz59uPvuu82OISIiIiIuRIVfamTx4sVYLBays7Nr7TkzMjKwWCysXbu21p5TRERExNOp8IuIiIiIuDEV/gYqPz+fESNGEBwcTJMmTXjhhRec7s/KymLIkCFYrVZSUlL4z3/+Q3JyMi+++KL9MRaLhTfeeINrrrmGwMBAUlNT+eyzz8742hkZGfTt2xeA8PBwLBYLo0aNAir2Npg8eTIpKSlYrVY6derEhx9+aP/eo0ePMmzYMKKiorBaraSmpjJr1iwAUlJSAOjSpQsWi4U+ffqcw09IRERERMDD5/CfTM+lt3Og5Ei9v26MXwTLek2v9uPvv/9+lixZwqeffkp0dDQTJkxg9erVdO7cGYBRo0axb98+Fi1ahK+vL3fddRdZWVknPM8TTzzBc889x/PPP8///d//MWzYMHbu3ElERMQpXzshIYH//e9/DB06lC1bthASEoLVagVg8uTJzJ07l1dffZXU1FS+//57hg8fTlRUFL1792bixIls3LiRr776isaNG7N9+3YKCwsB+Omnn7jgggtYsGAB7dq10066IiIiIrVAhf8PDpQcYV/RIbNjnFZeXh4zZ85k7ty59O/fH4DZs2cTHx8PwNatW/nqq6/46aefOP/88wGYOXMmbdq0OeG5Ro0axQ033ADAM888w8svv8xPP/3EZZdddsrX9/b2tv9CEB0dTVhYGADFxcU888wzLFiwgLS0NACaNWvG0qVLee211+jduze7du2iS5cudOvWDYDk5GT780ZFRQEQGRlJbGxsTX88IiIiIuJAhf8PYvxOfWTbVV53x44dlJSU0L17d/ttERERtGrVCoBNmzbh4+ND165d7fe3bt3aXswddezY0X45KCiIkJCQk34SUB3bt2+noKCASy65xOn2kpISunTpAsDtt9/O0KFDWb16NZdeeilXX301PXr0qNHriYiIiJjlpd/fZ/HhtaQENuHeZtcTb402O9IpqfD/wdksq3EHvr6+TtctFgs2m61Gz5WXlwfAvHnzaNq0qdN9/v7+AAwaNIidO3fy5Zdf8u2339K/f3/Gjh3Lv/71rxq9poiIiIgZVhzdyNcHVwJwV8qfTE5zejpptwFq3rw5vr6+rFy50n7b0aNH2bp1K1BxNL+srIxVq1bZ79+yZUutjtCsWl9fXl5uv61t27b4+/uza9cuWrRo4fSVkJBgf1xUVBQjR45k7ty5vPjii8yYMeOUzykiIiLiijIK9wPgbfEiPsB1j+6DjvA3SMHBwYwePZr777+fyMhIoqOjeeSRR/Dyqvj9rVWrVlx22WXcdtttTJ8+HR8fH+6++277ibW1ISkpCYvFwhdffMHgwYOxWq00atSI8ePHc88992Cz2ejVqxc5OTksW7aMkJAQRo4cyT/+8Q+6du1Ku3btKC4u5osvvrCfWxAdHY3VamX+/PnEx8cTEBBAaGhorWUWERERqQ2GYZBeUFH44/yj8PHyNjnR6ekIfwP1/PPPc9FFFzFkyBAGDBhAr169nNbsz5o1i7i4OHr37s21117LrbfeSnR07f322bRpU5544gkeeughYmJiuPPOOwF48sknmThxIpMnT6ZNmzZcdtllzJs3zz5y08/Pj4cffpiOHTty8cUX4+3tzbvvvguAj48PL7/8Mq+99hpxcXFcddVVtZZXREREpLYcLT1Gblk+AAnWKJPTnJnFMAzD7BB1KTc3l9DQUHJycggJCXG6r6ioiPT0dFJSUggICDApYf1JTk7m7rvv5u677zY7yjnxtPdNREREXMuq7C1c9OMdAPwlrj9vdp5Q7xlO13H/SEf4RURERETOws7CTPvllMA4E5NUjwq/nNSYMWMIDg4+6deYMWPMjiciIiJimvSCffbLzRpA4ddJux4kIyOj2o+dNGkS48ePP+l9Z/rYSERERMSdVZ2wC9AiKN7EJNWjwi8nFR0dXasn+YqIiIi4iwynwt/0NI90DVrSQ8VoJWk49H6JiIiImTIq1/AHe1uJ8HX9lQ8eXfirdpktKCgwOYmcjar364+7BIuIiIjUtTJbObsKDwCQYI3GYrGYnOjMPHpJj7e3N2FhYWRlZQEQGBjYIN40T2UYBgUFBWRlZREWFoa3t2tvciEiIiLuZ2/RQcqMcqCi8DcEHl34AWJjYwHspV9cX1hYmP19ExEREalPGYXH1+8nWZuYmKT6PL7wWywWmjRpQnR0NKWlpWbHkTPw9fXVkX0RERExjeOEnmaBKvwNire3t4qkiIiIiJyWc+F3/Qk94OEn7YqIiIiInA3HkZwtgxJMTFJ9KvwiIiIiItVUNZLTgoWkwIZxTqEKv4iIiIhINVUd4Y/xjyDA28/kNNWjwi8iIiIiUg3Hygo4WJINQEJAlLlhzoIKv4iIiIhINTiu30+wxpiY5Oyo8IuIiIiIVEPV+n2AlAYykhNU+EVEREREqiWjAY7kBBV+EREREZFqcZzB3yJIhV9ERERExK1kOBX+eBOTnB0VfhERERGRasgorCj8/l6+xPpHmJym+lT4RURERETOwGbYyCioOGk3PiAai8VicqLqU+EXERERETmDzOIjFNlKAEhsQCM5QYVfREREROSMdhYcH8mpwi8iIiIi4mbSCx1HcsaZmOTsqfCLiIiIiJyB40jOZkEq/CIiIiIibiWjYJ/9cmpQgolJzp4Kv4iIiIjIGWQ4rOHXkh4RERERETdTtYY/0jeUYB+ryWnOjgq/iIiIiMhpFJWXsK/oEADx1iiT05w9FX4RERERkdPYWdhwR3KCCr+IiIiIyGllOEzoSbY2MTFJzajwi4iIiIichuNIzpRAFX4REREREbeS4bDpVougeBOT1IwKv4iIiIjIaTiO5ExV4RcRERERcS9VS3p8LN6a0iMiIiIi4k4Mw7Av6YkLaIy3xdvkRGdPhV9ERERE5BQOl+ZyrKwAgISAhjeSE0wu/I8//jgWi8Xpq3Xr1vb7i4qKGDt2LJGRkQQHBzN06FAOHDhgYmIRERER8SSOIzkTA1X4a6Rdu3bs37/f/rV06VL7fffccw+ff/45H3zwAUuWLGHfvn1ce+21JqYVEREREU/iWPibNcCRnAA+pgfw8SE2NvaE23Nycpg5cybvvPMO/fr1A2DWrFm0adOGFStWcOGFF9Z3VBERERHxMOlOhT/OxCQ1Z/oR/m3bthEXF0ezZs0YNmwYu3btAmDVqlWUlpYyYMAA+2Nbt25NYmIiy5cvP+XzFRcXk5ub6/QlIiIiIlIT6Q4z+BviSE4wufB3796dt956i/nz5zN9+nTS09O56KKLOHbsGJmZmfj5+REWFub0PTExMWRmZp78CYHJkycTGhpq/0pISKjjP4WIiIiIuKudDjP4mzfQwm/qkp5BgwbZL3fs2JHu3buTlJTE+++/j9VqrdFzPvzww9x7773267m5uSr9IiIiIlIjVUt6GvkEEu7byOQ0NWP6kh5HYWFhtGzZku3btxMbG0tJSQnZ2dlOjzlw4MBJ1/xX8ff3JyQkxOlLRERERORsldnK2V1UMSEyISDa5DQ151KFPy8vjx07dtCkSRO6du2Kr68v3333nf3+LVu2sGvXLtLS0kxMKSIiIiKeYE9RFuWGDYAEa8McyQkmL+kZP348Q4YMISkpiX379vHYY4/h7e3NDTfcQGhoKKNHj+bee+8lIiKCkJAQ/v73v5OWlqYJPSIiIiJS5xwn9CRbT73CxNWZWvj37NnDDTfcwOHDh4mKiqJXr16sWLGCqKgoAKZOnYqXlxdDhw6luLiYgQMH8sorr5gZWUREREQ8hGPhT2mgM/jB5ML/7rvvnvb+gIAApk2bxrRp0+opkYiIiIhIBcdNt1o00Ak94GJr+EVEREREXEWGG8zgBxV+EREREZGTqlrSY8FCUmDDXcOvwi8iIiIichJVS3pi/SPw8/I1OU3NqfCLiIiIiPxBbmk+h0tzgYY9khNU+EVERERETpBRmGm/nGhtuJtugQq/iIiIiMgJnEZyWuNMTHLuVPhFRERERP4go2Cf/XKzoIY7gx9U+EVERERETuC4pKdFYIKJSc6dCr+IiIiIyB84LulpEdzUxCTnToVfREREROQPqkZyWr38ifYLNznNuVHhFxERERFxYDNs9iU98dYoLBaLyYnOjQq/iIiIiIiD/cWHKbGVAg1/Bj+o8IuIiIiIOMlwWL+fZI01MUntUOEXEREREXHgNIM/sGGP5AQVfhERERERJ46Fv3lgw57QAyr8IiIiIiJOdjrM4E8NijcxSe1Q4RcRERERceB4hL9ZUJyJSWqHCr+IiIiIiIOqwt/YL5RA7wCT05w7FX4RERERkUqF5cVkFh8GICGg4Y/kBBV+ERERERE7x/X7CdZoE5PUHhV+EREREZFKjuv3kwMb/gx+UOEXEREREbFz3HSrmRuM5AQVfhERERERO8fC3yJIhV9ERERExK2kFx4v/C2DEkxMUntU+EVEREREKlUd4fe1eNMkINLkNLVDhV9EREREBDAMw37SbtOAaLwt3iYnqh0q/CIiIiIiwKGSHPLLiwD3GckJKvwiIiIiIoDz+v1Eq3tsugUq/CIiIiIigPOEnpTAJiYmqV0q/CIiIiIiOG+61dxNZvCDCr+IiIiICOB8hD81KN7EJLVLhV9EREREBMhwWMPf3E023QIVfhERERER4PiSnlCfIEJ9g01OU3tU+EVERETE45XaythTeBCABDea0AMq/CIiIiIi7C7MwoYNcK8Z/KDCLyIiIiJCesE+++Uka6yJSWqfCr+IiIiIeDzHTbeaBcaZmKT2qfCLiIiIiMfbWZBpv9zCjWbwgwq/iIiIiIjTplupQQkmJql9KvwiIiIi4vGqCr8XFhIDNaVHRERERMStVG261SSgMb5ePianqV0q/CIiIiLi0bJL8zhaegyAhAD3GskJKvwiIiIi4uEyHNbvJ7rZplugwi8iIiIiHs6x8CcHutcMflDhFxEREREPl1F4fCRnczcbyQkq/CIiIiLi4RxHcrYIijcxSd1Q4RcRERERj+ZY+JsH6Qi/iIiIiIhbySjYB0Cgtz9RfmHmhqkDKvwiIiIi4rHKjXJ2FWUBkBAQg8ViMTlR7VPhFxERERGPtb/oMCW2UgASrO43gx9U+EVERETEg6W7+Qx+UOEXEREREQ/mWPibBcaZmKTuqPCLiIiIiMfKKHTvkZygwi8iIiIiHizDaQa/+43kBBV+EREREfFgjkt6UrSkR0RERETEvWQUZgIQ7ReO1dvf5DR1Q4VfRERERDxSQXkRB4qPAO47khNU+EVERETEQ2UUZNovxweo8IuIiIiIuJX0gn32yymBTUxMUrdU+EVERETEI+0sPH6Ev1mge07oARV+EREREfFQjhN6Ut10JCeo8IuIiIiIh3Is/M3ddNMtUOEXEREREQ9VtemWr8WHuIBIk9PUHRV+EREREfE4hmHYZ/AnWKPxsrhvLXbfP5mIiIiIyClklRyloLwIcO8Z/KDCLyIiIiIeKMNh/X5CQIyJSeqeCr+IiIiIeBzHE3abBcaZmKTuqfCLiIiIiMfJcJjB39yNR3KCCr+IiIiIeCBPmcEPKvwiIiIi4oEynJb0qPCLiIiIiLiVqsIf7tuIEN8gk9PULRV+EREREfEoJbZS9hQdBCAhwL1HcoIKv4iIiIh4mF2FBzAwAIh38xn8oMIvIiIiIh7G8YTd5MAmJiapHyr8IiIiIuJRMgqOj+R09xn8oMIvIiIiIh4mo3Cf/XILFX4REREREffiuKSnRVC8iUnqhwq/iIiIiHiUqsLvbfEiwRpjcpq6p8IvIiIiIh5lZ+Ua/jj/xvh6+Zicpu6p8IuIiIiIxzhaeozssjwAEjxgJCeo8IuIiIiIB3Fcv+8Jy3nAhQr/s88+i8Vi4e6777bfVlRUxNixY4mMjCQ4OJihQ4dy4MAB80KKiIiISIO206Hwp1jdfwY/uEjh//nnn3nttdfo2LGj0+333HMPn3/+OR988AFLlixh3759XHvttSalFBEREZGGzvEIf7Mg9x/JCS5Q+PPy8hg2bBivv/464eHh9ttzcnKYOXMmU6ZMoV+/fnTt2pVZs2bx448/smLFChMTi4iIiEhD5TSSM9D9R3KCCxT+sWPHcvnllzNgwACn21etWkVpaanT7a1btyYxMZHly5ef8vmKi4vJzc11+hIRERERAcgodCj8wZ5R+E2dQ/Tuu++yevVqfv755xPuy8zMxM/Pj7CwMKfbY2JiyMzMPOHxVSZPnswTTzxR21FFRERExA1kVI7kDPK2EukbYnKa+mHaEf7du3czbtw4/vOf/xAQEFBrz/vwww+Tk5Nj/9q9e3etPbeIiIiINFzlRjk7CysKf6I1GovFYnKi+mFa4V+1ahVZWVmcd955+Pj44OPjw5IlS3j55Zfx8fEhJiaGkpISsrOznb7vwIEDxMbGnvJ5/f39CQkJcfoSEREREdlbdIgyoxyA+ADPmMEPJi7p6d+/P+vXr3e67aabbqJ169Y8+OCDJCQk4Ovry3fffcfQoUMB2LJlC7t27SItLc2MyCIiIiLSgKUX7LNfTgo89QFkd2Na4W/UqBHt27d3ui0oKIjIyEj77aNHj+bee+8lIiKCkJAQ/v73v5OWlsaFF15oRmQRERERacCq1u8DNAv0jBn8YPJJu2cydepUvLy8GDp0KMXFxQwcOJBXXnnF7FgiIiIi0gA5juRs7iEjOcHFCv/ixYudrgcEBDBt2jSmTZtmTiARERERcRsZjjP4g5qamKR+mT6HX0RERESkPjjO4E8J9IxddkGFX0REREQ8RNUR/hj/CAK8/UxOU39U+EVERETE7eWVFZJVkg1AogeN5AQVfhERERHxAI7r9+OtKvwiIiIiIm4lo/D4SM4UDxrJCSr8IiIiIuIBHI/wNwv0nAk9oMIvIiIiIh4g3UNHcoIKv4iIiIh4gPSCffbLLYI8Z9MtUOEXEREREQ+ws3INv7+XL7H+ESanqV8q/CIiIiLi1gzDsC/piQ+IxsviWRXYs/60IiIiIuJxMouPUGQrASDBw0Zyggq/iIiIiLg5xwk9idYYE5OYQ4VfRERERNxaRqHjSM44E5OYQ4VfRERERNya40jO5h42khNU+EVERETEzTku6UkN9KyRnKDCLyIiIiJuLqNyJCdASpCW9IiIiIiIuJWqJT0RviE08gk0OU39U+EXEREREbdVVF7CvqJDgGeO5AQVfhERERFxY7sKD2BgAJAQoMIvIiIiIuJWHEdyJgc2MTGJeVT4RURERMRtOY7k9MQZ/KDCLyIiIiJuLMPDZ/CDCr+IiIiIuLF0D5/BDyr8IiIiIuLGqmbw+1i8ideUHhERERER92EYhn1JT1xAY3y8vE1OZA4VfhERERFxS0dKc8ktywc8dyQnqPCLiIiIiJvKKMi0X060xpiYxFwq/CIiIiLilhxn8Kd46EhOUOEXERERETflNIM/SIVfRERERMStOI3kDPLMkZygwi8iIiIibmqn46ZbgZ656Rao8IuIiIiIm0qvXMPfyCeQcN9GJqcxjwq/iIiIiLidMls5uwoPABAfEI3FYjE5kXlU+EVERETE7ewpyqLcsAGQ6KE77FZR4RcRERERt+M4gz/JGmtiEvOp8IuIiIiI20kv3Ge/3MyDZ/CDCr+IiIiIuCGnGfwePKEHVPhFRERExA3tdFjS0zI4wcQk5lPhFxERERG3U3WE34KFJGuMyWnMpcIvIiIiIm4no3IGf6x/BP7efianMZcKv4iIiIi4lWNlBRwqyQEg3sNHcoIKv4iIiIi4mQyHE3YTAzx7OQ/UsPDPnz+fpUuX2q9PmzaNzp0789e//pWjR4/WWjgRERERkbPlOKEnOdCzZ/BDDQv//fffT25uLgDr16/nvvvuY/DgwaSnp3PvvffWakARERERkbORoZGcTnxq8k3p6em0bdsWgP/9739cccUVPPPMM6xevZrBgwfXakARERERkbORXni88KcGqfDX6Ai/n58fBQUFACxYsIBLL70UgIiICPuRfxERERERM2Q4zOBv4eEz+KGGR/h79erFvffeS8+ePfnpp5947733ANi6dSvx8fG1GlBERERE5GxULekJ8PIjxi/c5DTmq9ER/n//+9/4+Pjw4YcfMn36dJo2rfio5KuvvuKyyy6r1YAiIiIiItVlM2z2Gfzx1mgsFovJicxXoyP8iYmJfPHFFyfcPnXq1HMOJCIiIiJSU/uLD1NsKwUgIUAz+OEsCv/ZrM0PCQmpURgRERERkXOx02H9fpJVM/jhLAp/WFhYtT8SKS8vr3EgEREREZGacpzB30wTeoCzKPyLFi2yX87IyOChhx5i1KhRpKWlAbB8+XJmz57N5MmTaz+liIiIiEg1OBX+wDgTk7iOahf+3r172y9PmjSJKVOmcMMNN9hvu/LKK+nQoQMzZsxg5MiRtZtSRERERKQadjrN4Nf0SKjhlJ7ly5fTrVu3E27v1q0bP/300zmHEhERERGpCR3hP1GNCn9CQgKvv/76Cbe/8cYbJCRocwMRERERMUdV4Y/0DSXIx2pyGtdQo7GcU6dOZejQoXz11Vd0794dgJ9++olt27bxv//9r1YDioiIiIhUR2F5MfuLDwOQYNVIzio1OsI/ePBgtm3bxpVXXsmRI0c4cuQIQ4YMYevWrQwePLi2M4qIiIiInNGuwgP2y4kq/HZnfYS/tLSUyy67jFdffZWnn366LjKJiIiIiJw1x/X7yYFNTEziWs76CL+vry/r1q2riywiIiIiIjXmWPhTdMKuXY2W9AwfPpyZM2fWdhYRERERkRrLKNhnv9wiUJtuVanRSbtlZWW8+eabLFiwgK5duxIUFOR0/5QpU2olnIiIiIhIdWUUZtovawb/cTUq/Bs2bOC8884DYOvWrU73WSyWc08lIiIiInKWMiqX9PhavGlqjTI5jeuoUeFftGhRbecQEREREakxwzDsa/jjAqLwtnibnMh11GgNv4iIiIiIKzlcmkteeSGgGfx/VKMj/AC//PIL77//Prt27aKkpMTpvo8++uicg4mIiIiIVJfjhJ5Ea4yJSVxPjY7wv/vuu/To0YNNmzbx8ccfU1paym+//cbChQsJDQ2t7YwiIiIiIqflOKGnmUZyOqlR4X/mmWeYOnUqn3/+OX5+frz00kts3ryZ6667jsTExNrOKCIiIiJyWo5H+FX4ndWo8O/YsYPLL78cAD8/P/Lz87FYLNxzzz3MmDGjVgOKiIiIiJyJRnKeWo0Kf3h4OMeOHQOgadOmbNiwAYDs7GwKCgpqL52IiIiISDVkOBzhb67C76RGJ+1efPHFfPvtt3To0IE///nPjBs3joULF/Ltt9/Sv3//2s4oIiIiInJaVUt6QnyCCPMNNjmNa6lR4f/3v/9NUVERAI888gi+vr78+OOPDB06lEcffbRWA4qIiIiInE6prYzdhVmARnKeTI0Kf0REhP2yl5cXDz30UK0FEhERERE5G3uKsrBhAyAhQIX/j2q0hn/EiBHMmjWLHTt21HYeEREREZGz4jihJzmwiYlJXFONCr+fnx+TJ08mNTWVhIQEhg8fzhtvvMG2bdtqO5+IiIjUs8WH1rDk8BqzY4hUm2PhT7Gq8P9RjQr/G2+8wdatW9m9ezfPPfccwcHBvPDCC7Ru3Zr4eJ0VLSIi0lAtObyGwT+NZ9DK8byx63Oz44hUy86C4yM5WwQ1NTGJa6pR4a8SHh5OZGQk4eHhhIWF4ePjQ1RUVG1lExERkXr2v/1L7JfHb5zG+lwt3xXXl154/Ah/alCCiUlcU40K/4QJE+jRoweRkZE89NBDFBUV8dBDD5GZmcmaNfoIUEREpKFyXMpTYitl2JpJ5JUVmphI5MyqlvR4YSExMMbkNK6nRlN6nn32WaKionjssce49tpradmyZW3nEhERkXq2p/Ag2/L3ON22PX8P4357kZmdHjYplciZZRTsAyDWPxI/L1+T07ieGh3hX7NmDY888gg//fQTPXv2pGnTpvz1r39lxowZbN26tbYzioiISD1YfHi1/fLVsRcR7G0F4L97FzB3z9dmxRI5rZzSPI6UHgM0g/9UalT4O3XqxF133cVHH33EwYMH+fLLL/Hz82Ps2LG0adOmtjOKiIhIPXBcznNzwhD+3eFe+/VxG15ic95OM2KJnFZG4fETdhOtWs5zMjVa0mMYBmvWrGHx4sUsXryYpUuXkpubS8eOHendu3dtZxQREZE6ZhgGiyoLf4CXH70iO+Ln5cviw2t4a/eXFNqKGbZ6Ekt7voLV29/ktCLHOc3g10jOk6rREf6IiAi6d+/OO++8Q2pqKrNnz+bQoUOsXr2aqVOnVvt5pk+fTseOHQkJCSEkJIS0tDS++uor+/1FRUWMHTuWyMhIgoODGTp0KAcOHKhJZBERETmN7fl72Fd0CIBuYa3t66D/1XYsbYKTAdiUl8H4jdPMiihyUhkOhb95UJyJSVxXjQr/3LlzOXz4ML/88gsvvPACQ4YMISws7KyfJz4+nmeffZZVq1bxyy+/0K9fP6666ip+++03AO655x4+//xzPvjgA5YsWcK+ffu49tpraxJZRERETmORw3KeiyI62S8Hegcwt8tErF4VR/Vn7Z7HB/sW1ns+kVNxLPwtNJLzpGpU+C+//HJCQkLYvn07X3/9NYWFFeO6DMM4q+cZMmQIgwcPJjU1lZYtW/L0008THBzMihUryMnJYebMmUyZMoV+/frRtWtXZs2axY8//siKFStqEltEREROwXH9/qVR5zvd16ZRMlPb3WW/Pnb9FHbk7623bCKn4ziDX5tunVyNCv/hw4fp378/LVu2ZPDgwezfX/GDHj16NPfdd1+NgpSXl/Puu++Sn59PWloaq1atorS0lAEDBtgf07p1axITE1m+fPkpn6e4uJjc3FynLxERETk1m2Hj+8NrAQjxCaJbWOsTHnNj/EBuiKv4NzmvvJDhayZRXF5SnzFFTqrqCL/Vy58ovzBzw7ioGhX+e+65B19fX3bt2kVgYKD99uuvv5758+ef1XOtX7+e4OBg/P39GTNmDB9//DFt27YlMzMTPz+/E5YKxcTEkJmZefInAyZPnkxoaKj9KyFBH+2IiIiczrrcHRwurThA1j2sLd4W7xMeY7FYeLH9OFoExQPwa+52JmyeUa85Rf7IZtjYWVhxfmeCNRqLxWJyItdUo8L/zTff8M9//pP4+Hin21NTU9m58+xGdrVq1Yq1a9eycuVKbr/9dkaOHMnGjRtrEguAhx9+mJycHPvX7t27a/xcIiIinsBxOc/FkZ1P+bhGPoHM6TIR/8oTeqfv/JjPMpfWdTyRU9pXdJgSWykACRrJeUo1Kvz5+flOR/arHDlyBH//sxvV5efnR4sWLejatSuTJ0+mU6dOvPTSS8TGxlJSUkJ2drbT4w8cOEBsbOwpn8/f398+9afqS0RERE7N8YTdy6K6n/axnUJa8M82d9iv37buOXYVaoKemCPDYf1+kgr/KdWo8F900UW8/fbb9usWiwWbzcZzzz1H3759zymQzWajuLiYrl274uvry3fffWe/b8uWLezatYu0tLRzeg0RERGpUGorY9mRdQBE+4XTtlHyGb/nlsQhXBN7MQA5ZfncuHoSpbayuowpclLpBfvsl1MCNYP/VGq08dbzzz9Pv379+OWXXygpKeGBBx7gt99+48iRIyxbtqzaz/Pwww8zaNAgEhMTOXbsGO+88w6LFy/m66+/JjQ0lNGjR3PvvfcSERFBSEgIf//730lLS+PCCy+sSWwRERH5g1+yN5NfXgTAheHtqrUG2mKxMK3DfazJ2UpGYSY/52zm8S1v8nSbW+s6roiTjILj53W2CIw/zSM921kX/tLSUu666y4+//xzvv32Wxo1akReXh7XXnstY8eOpUmT6v92lZWVxYgRI9i/fz+hoaF07NiRr7/+mksuuQSAqVOn4uXlxdChQykuLmbgwIG88sorZxtZRERETmGxw3KePpFdqv19Yb7BvN1lIv2Xj6PUKGNq+nv0btyZS6MuqIuYIiflPINfhf9ULMbZDs8HoqKi+PHHH0lNTa2LTLUqNzeX0NBQcnJytJ5fRETkDwauuJcfjvwKwG995pASeHY7lf5f+oc8uGk6ABG+Ifx00evEBTSu9ZwiJ9Nv+V2sOFqxYeuhgfMI9A4wOVH9OZuOW6M1/MOHD2fmzJk1CiciIiKuoaC8iJXZFZPxEgJizrrsA9yZPJRB0RVLbY+U5jJyzVOUG+W1mlPkVNIrj/BH+YV5VNk/WzVaw19WVsabb77JggUL6Nq1K0FBQU73T5kypVbCiYiISN1ZfmSDfaRhj4j2NXoOi8XCjI4PcOHSW9lbdIhlR9czedscHm05qhaTipyooLyIA8VHgIoZ/HJqNSr8GzZs4LzzzgNg69atTvdpwwMREZGGwXH9fr/GXWv8PJF+oczu/CgDV95LuWFj8va59IroRJ/G1T8nQORs7XQ4YTchQCM5T6dGhX/RokW1nUNERETqmWPhv6Rxt3N6rh4RHZiYOorHt76JgcGotU/z00WvE+0ffq4xRU4q3eGE3eTAU+/RJDVcwy8iIiINW3ZpHmtytgHQKiiR2IDIc37O8c1voF9kxScFWSVH+dvaydgM2zk/r8jJOG661TywqYlJXJ8Kv4iIiAf64civ2Kgo42nhNVu//0deFi9mdn6IaL+Ko/oLD69iyu/v1cpzi/yR4wz+5kEq/Kejwi8iIuKBFh86vpxnwDms3/+jGP8IZnWegIWKc/qe2Pomy49sqLXnF6niuKQnNSjBxCSuT4VfRETEAy0+vBoALyzndMLuyfRtfB4PthgGQLlhY8TapzhcklOrryFStemWr8WHuFpYkubOVPhFREQ8TGbxETbl7QSgQ0hzwvwa1fprTGgxgl7hHQHYW3SQW399jhrs9SlyUoZh2Nfwx1uj8LKo0p6OfjoiIiIeZonDcp6eER3q5DV8vLyZ1WUCEb4VO4B+dXAF0zI+qpPXEs9zsCSb/PIiQCM5q0OFX0RExMM4juMc0Pj8OnudpgFRvNHpIfv1Rza/xi/Zm+vs9cRzZDis30+0qvCfiQq/iIiIh6kq/H5evvSO7Fynr3VZdHfuaXYdAKVGOTeumUROaV6dvqa4P8cTdlMCm5iYpGFQ4RcREfEgGQX72VlYMc7wvJCWWL396/w1H285mgvC2gCws/AAt6//l9bzyznJKHQcyRlnYpKGQYVfRETEgyyqnM4D0CuiY728pq+XD7M7P0qoTzAAn2T+wBu7vqiX1xb3lF6wz35ZIznPTIVfRETEgzjO378kqu7W7/9RUmAsr3a83379gU3TWJ+7o95eX9yL4xr+ZoE6wn8mKvwiIiIewjAMllSu3w/yttbaDrvVdVVsL25PugaAYlspw9ZMIq+ssF4ziHuoWsMf5hNMqG+wyWlcnwq/iIiIh9iYl0FWSTYAF4S1wcfLu94zPNP6VjqHpAKwPX8P4357sd4zSMNWYitlb9EhABKs0SanaRhU+EVERDzEEodxnBdHdDIlg7+3H293eZRgbysA/927gLl7vjYlizRMuwuzsGEDIEEjOatFhV9ERMRDLHJYv39p9AWm5WgRFM+/O9xrvz5uw0tsrtz5V+RMHEdyJqnwV4sKv4iIiAcos5Xzw5FfAQj3bUSnkBam5rkurh+jEgYDUGgrZtjqJygsLzY1kzQMGYU6YfdsqfCLiIh4gDW528gtywcgLbw9XhbzK8C/2o6lTXAyAJvydjJ+4zRzA0mD4Dihp0VQvIlJGg7z/7aLiIhInVt86Pj8/breXbe6Ar0DmNtlIlavis2/Zu2exwf7FpqcSlyd45KeVBX+alHhFxER8QCOJ+wOjDJv/f4ftWmUzNR2d9mvj10/hR35e01MJK6uqvB7YdFJu9Wkwi8iIuLmispL+PHoBgDi/Bu73M6kN8YP5Ia4AQDklRcyfM0kistLTE4lrmpnYSYAcQGN8fXyMTlNw6DCLyIi4uZ+yt5Ika2iQKeFt8NisZicyJnFYuHF9uPs67F/zd3OhM0zTE4lruho6TGOlh4DNJLzbKjwi4iIuLlFDst5+jY+z8Qkp9bIJ5A5XSbi7+ULwPSdH/NZ5lKTU4mrcTxhNyFAm25Vlwq/iIiIm3PV9ft/1CmkBf9sc4f9+m3rnmNX4QETE4mrcSz8KYFNTEzSsKjwi4iIuLFjZQX8kr0ZgOaBcTS1uvZR0VsSh3BN7MUA5JTlc+PqSZTaykxOJa4io3L9PlT8/1mqR4VfRETEjS09so4yoxyAC8Pbm5zmzCwWC9M63EeyNRaAn3M28/iWN01OJa4i3WkGv2udfO7KVPhFRETcmONynv6Nu5mYpPrCfIN5u8tEfC0VE1impr/H11krTU4lrsBxSU/zoKYmJmlYVPhFRETc2KJDFYXfgoVLGkjhB+gW1pqnWt9ivz7612fZV3TIxETiCqqO8Ad5B9DYL9TkNA2HCr+IiIibOlSSw/pjOwBo2yiZSP+GVZDuTB7KoOgLAThSmsvINU9RXrk8STxPuVFuP4k7wRrtcuNlXZkKv4iIiJv6/vBa++We4R3MC1JDFouFGR0foGlAYwCWHV3P5G1zTE4lZtlXdIhSo+IE7oQAzeA/Gyr8IiIibmqx0/r9riYmqblIv1Bmd34Ub0tFZZm8fS6LD605w3eJO3I8YTdRm26dFRV+ERERN7X40GoAfCze9GughR+gR0QHJqaOAsDAYNTap8kqPmpuKKl3GQXHR3I200jOs6LCLyIi4ob2FGaxvWAvAJ1DUgnysZqc6NyMb34D/SIrfmnJKjnK39ZOxmbYTE4l9Sm90HEkpyb0nA0VfhERETfkuJynZ0TDW7//R14WL2Z2fohov3AAFh5exZTf3zM5ldSnDKcZ/PEmJml4VPhFRETckGPhv6Tx+SYmqT0x/hHM6jwBCxXTWZ7Y+ibLj2wwOZXUl/SCffbLKVrSc1ZU+EVERNyMYRj2wm/18qdXZEeTE9Wevo3P48EWwwAoN2yMWPsUh0tyTE4l9aFqDX+MXzgB3n4mp2lYVPhFRETczLb8PfZNqrqFtcbPy9fkRLVrQosR9Aqv+CVmb9FBbv31OQzDMDmV1KX8skKySipO1E7QhJ6zpsIvIiLiZhyX81wU4T5H96v4eHkzq8sEInxDAPjq4AqmZXxkciqpSxmFxyf0xFujTEzSMKnwi4iIuJnFh1fbL18adYGJSepO04Ao3uj0kP36I5tf45fszSYmkrrkOIM/xdrExCQNkwq/iIiIG7EZNvsOuyE+QXQNa2VuoDp0WXR37ml2HQClRjk3rplETmmeyamkLux0KPzNNJLzrKnwi4iIuJF1uTs4UnoMgAvD2+Jt8TY5Ud16vOVoLghrA8DOwgPcvv5fWs/vhhxn8KdqJOdZU+EXERFxI47r9y+O6GxekHri6+XD7M6PEuoTDMAnmT/wxq4vTE4ltc1xSU9zHeE/ayr8IiIibsSx8A+M6m5ikvqTFBjLqx3vt19/YNM01ufuMDGR1LadlSM5/bx8aeIfaXKahkeFX0RExE2U2EpZdmQdANF+4bRtlGxuoHp0VWwvbk+6BoBiWynD1kwir6zQ5FRSGwzDsB/hTwiIwsui+nq29BMTERFxE79kbya/vAiAC8PbYbFYTE5Uv55pfSudQ1IB2J6/h3G/vWhuIKkVB0qOUmgrBjSDv6ZU+EVERNyE43KevpFdTExiDn9vP+Z0mUiwtxWA/+5dwNw9X5ucSs5VhsP6/QRrtIlJGi4VfhERETfhWPgvjXbP+ftn0jyoKf/ucK/9+rgNL7E5b6eJieRcORb+ZoE6YbcmVPhFRETcQEF5ESuPbgQg0RpDSmCcyYnMc11cP0YlDAag0FbMsNVPUFhebHIqqSmnCT0e/P/rc6HCLyIi4gZ+PLKBUqMMgLTw9ianMd+/2o6lTXAyAJvydjJ+4zRzA0mNORb+FhrJWSMq/CJyghVHf+PVjE90REykAVnisJynX+OuJiZxDYHeAcztMhGrlz8As3bP44N9C01OJTWRUaglPedKhV9EnOwsyGTwyvHcu/H/GLb6Ce1YKdJALHIo/Jc07mZiEtfRplEyU9vdZb8+dv0UduTvNTGR1ERG5Qz+cN9GhPgGmZymYVLhFxEnM3d/QZGtBID5B1fyf+kfmpxIRM7kaOkx1uRsBaBVUCKxAdqYqMqN8QO5IW4AAHnlhQxfM4ni8hKTU0l1FZeXsLfoIFBxborUjAq/iNiV2Ep5e/dXTrc9uuV1fs7ebFIiEamOHw7/ikHFp3E9IrR+35HFYuHF9uNoERQPwK+525mweYbJqaS6dhUesP9/Oz4gyuQ0DZcKv4jYfZa5lKySbAAa+QQCUGaUM2LNJHJK80xMJiKn4ziOs3+k1u//USOfQOZ0mYi/ly8A03d+zGeZS01OJdWRUZhpv5wc2MTEJA2bCr+I2L2+63P75ZkdH+KCsDYA7Cw8wB3rX9B6fhEXVXXCrrfFi/5av39SnUJa8M82d9iv37buOXYVHjAxkVRHutMMfo3krCkVfhEBYHPeTn448itQ8R/Vy2N6MLvzo4T6BAPwceb3zNz9hZkRReQk9hcdZlPlxlLtGzUj1C/Y5ESu65bEIVwTezEAOWX53Lh6EqW2MpNTyek4brrVQhN6akyFX0QAeMPh6P7w+IFYLBaSAmOZ3nG8/fb7N77ChtzfzYgnIqfw/eG19ss9IzqYF6QBsFgsTOtwH8nWWAB+ztnM41veNDmVnI7zDP54E5M0bCr8IkJBeRH/2fMNAP5evtySOMR+39WxF3Fb0lUAFNtKGLZmEvllhabkFJETLTq82n75ksbnm5ikYQjzDebtLhPxtfgAMDX9Pb7OWmlyKjmVqhn83hYvEjSlp8ZU+EWED/YtIqcsH4AronsQ6RfqdP/k1mPo2Kg5ANvyd3PPby/Xe0YROZFhGPYTdv28fLk4srO5gRqIbmGtear1Lfbro399ln1Fh0xMJCdjGIb9CH+cfxQ+Xt4mJ2q4VPhFxGk5z21JV59wf4C3H3O6TCTIOwCAuXu/4b97v62veCJyChmF++0nnnYNbYXV29/kRA3HnclDGRR9IQBHSnMZueYpyo1yk1OJo6Olx8itPBiVYNVIznOhwi/i4VbnbGVVzhYA2gYnn3INcGpwAi+1v9t+/e8bXmRb3u76iCgip7Do0PFxnL0iOpqYpOGxWCzM6PgATQMaA7Ds6Homb5tjcipx5Lh+X5tunRsVfhEP53h0f2TCICwWyykf+9emlzC86aVAxbr/4WsmUaQdK0VMs8Rh/v4lGsd51iL9Qpnd+VG8LRV1aPL2uSx2+CVKzLXTYQZ/ikZynhMVfhEPllOax/v7FgIQ5G1lVPzgM37PlHZ30TIoAYD1x37n4c2v1mlGETk5wzDshT/I28qF4dphtyZ6RHRgYuooAAwMRq19mqzio+aGEgDSC/bZL2sG/7lR4RfxYO/sXUBBeREA18ReTCPfwDN+T7CP1WnHytd2fsqn2rFSpN5tzMuw74x9QVgbndB4DsY3v4F+lTsUZ5Uc5W9rJ2MzbCanEo3krD0q/CIeyjAM3tj1mf367Sc5WfdUOoQ057k2Y+3Xx2jHSpF6t/jQ8XGcvTWd55x4WbyY2fkhov3CAVh4eBVTfn/P5FTiuKSnRZA23ToXKvwiHurHo+vtu3N2C21Nl7CWZ/X9NydeoR0rRUy0yHH9fpTm75+rGP8IZnWegIWK85ie2Pomy49sMDmVZ6s6wh/sbSXCN8TkNA2bCr+Ih3p95/GTdUclDDrr76/asTKpcnLCzzmbeWKrdqwUqQ9ltnKWHlkHQIRvCJ1CWpicyD30bXweD7YYBkC5YWPE2qc4XJJjcirPVGYrt39ynGCNOe1ACTkzFX4RD5RVfJSPM78HINy3EX+Nu6RGz1OxY+U/8LFUrB2e8vt7fHvw51rLKSIntzp3q30++YXh7fCy6J/z2jKhxQh6hVeMON1bdJBbf30OwzBMTuV59hYdpKxyXwTN4D93+i+EiAeas2c+pUbF8ps/NelDgE/NN+s5P6w1T7a62X79b2sns7/o8DlnFJFTW+IwOrJPZBcTk7gfHy9vZnWZYF9C8tXBFUzL+MjkVJ4no/D4CbtJ1lgTk7gHFX4RD2MzbMzcNc9+/Y7ka8/5Of+e8icGRnUH4HBpDjetfUY7VorUocUO6/cv1fr9Wtc0IIo3Oj1kv/7I5tf4JXuziYk8j+OEHo3kPHcq/CIeZsGhX+xHTnpFdKRVcOI5P6eXxYvXOz1IE/9IAL4/spbnt79zzs8rIicqKi9h+dGKk0nj/BuTWrkvhtSuy6K7c0+z6wAoNcq5cc0kckrzTE7lORwLf/NAjeQ8Vyr8Ih7GcWfd0QlX1NrzNvYL5a3Oj+BV+Z+Vp7bNtp9UKCK1Z2X2bxTZKna4Tgtvp5MZ69DjLUdzQVgbAHYWHuD29f/Sev56kuFQ+FM1g/+cqfCLeJA9hVl8eWAFUDGCbmiTPrX6/BdFduLh1BsBsGEwcs1THNKEC5Fatchh/X7fxueZmMT9+Xr5MLvzo4T6BAPwSeYPvLHrC5NTeYaMyhn8FiwkBWoN/7lS4RfxILN2f4mNit0j/xI3oE525nyoxTAujugEwP7iw9z66z91REykFi1xWL8/MOoCE5N4hqTAWF7teL/9+gObprEud4eJiTxD1RH+GP8IArz9TE7T8Knwi3iIUlsZs3Z/CYC3xeusdtY9G94Wb97sPIFI31AA5h9cyb8z/lcnryXiaXJL8/klp+Lk0eaBcTS1RpucyDNcFduL25OuAaDYVsrwNZPIKys0OZX7OlZWwMGSbAASAjSSszao8It4iHlZy8ksrhiX2b9xVxIDY+rsteICGvNGpwft1x/dPINV2Vvq7PVEPMWyo+spNyo+pUsL72ByGs/yTOtb6RySCsD2/D2M++1FcwO5Mcf1+wnWuvu3ypOo8It4iDd2fma/PDphSJ2/3kBNuBCpdYsPrbZf7te4q4lJPI+/tx9zukwk2NsKwH/3LmDunq9NTuWeqtbvA6QENjExiftQ4RfxANvz97DwcEVRSLTGcHlMWr287uMtR3N+aGug4j/gY9dP0Xp+kXOw+PBaoOJExksadzM3jAdqHtSUaR3utV8ft+ElNuftNDGRe8pwmsHf1MQk7sPUwj958mTOP/98GjVqRHR0NFdffTVbtjh/7F9UVMTYsWOJjIwkODiYoUOHcuDAAZMSizRMMx2mSgxreilelvr5q+/r5cPbXSYS4hMEwEeZS3hz97wzfJeInMzB4mzWH6s4WbRto2Qi/UNNTuSZ/hzXj1EJgwEotBUzbPUTFJYXm5zKvTjO4G8RpMJfG0wt/EuWLGHs2LGsWLGCb7/9ltLSUi699FLy8/Ptj7nnnnv4/PPP+eCDD1iyZAn79u3j2mvPfWdQEU9RVF7CnD3zAfC1+HBr0pX1+vpJgbG82mG8/fr4jdPYkPt7vWYQcQffH1lrv9xT6/dN9a+2Y2kTnAzAprydjN84zdxAbibDqfBrBn9tMLXwz58/n1GjRtGuXTs6derEW2+9xa5du1i1ahUAOTk5zJw5kylTptCvXz+6du3KrFmz+PHHH1mxYoWZ0UUajI8yl3Ck9BgAg6IvJMY/ot4zXN3kYm5JrPhFo9hWwvA1k8jXhAuRs7LYYf7+gCgt5zFToHcAc7tMxOrlD8Cs3fP4YN9Ck1O5j6rd4P29fIk14d8sd+RSa/hzcio26ImIqHhzV61aRWlpKQMGDLA/pnXr1iQmJrJ8+fKTPkdxcTG5ublOXyKezHFn3duSrjItxz/b3E77Rs0A2Jq/m/s2/tu0LCIN0eLK+fu+Fm/6RmrDLbO1aZTM1HZ32a+PXT+FHfl7TUzkHmyGjYyCipN2E6wx2km6lrhM4bfZbNx999307NmT9u3bA5CZmYmfnx9hYWFOj42JiSEzM/Mkz1JxXkBoaKj9KyEhoa6ji7is9bk7WHH0NwBaBiXQJ7KLaVkCKidcBHkHAPD2nvm8t/c70/KINCS7Cw+wo6CiTHYOSSXIx2pyIgG4MX4gN8RVHJTMKy9k+JpJFJeXmJyqYcssPkKRreJnmBCgfSZqi8sU/rFjx7Jhwwbefffdc3qehx9+mJycHPvX7t27aymhSMPjuAX8iPjLTD9S0io4kRfbjbNfv3PDFLbn7zExkUjDsNhhd90eEVq/7yosFgsvth9nX2f+a+52JmyeYXKqhm1nwfEDuomawV9rXKLw33nnnXzxxRcsWrSI+PjjJ2fExsZSUlJCdna20+MPHDhAbGzsSZ/L39+fkJAQpy8RT3SsrID/7v0WgEBvf/6WcLnJiSoMi7+UYU0vASC/vIjhq3VETORMllSO4wS4NOoC84LICRr5BDKny0T8vXwBmL7zYz7LXGpyqoYrvdBxJGeciUnci6mF3zAM7rzzTj7++GMWLlxISkqK0/1du3bF19eX7747/rH/li1b2LVrF2lp9TNHXKShenfvd+SVV5wYe2VML8L8Gpmc6Lip7caRWnlEbN2xHTy8+TWTE4m4LsMwWFS54ZbVy5+eOsLvcjqFtOCfbe6wX79t3XPsKtQI8ZpwHMnZLEiFv7aYWvjHjh3L3Llzeeedd2jUqBGZmZlkZmZSWFhRUkJDQxk9ejT33nsvixYtYtWqVdx0002kpaVx4YUXmhldxKUZhuF0su6YpKvNC3MSwT5W5nT5h/2I2Ks7P9ERMZFT2Jq/m/3FhwHoFtYav8q/N+JabkkcwjWxFwOQU5bPjasnUWorMzlVw5NRsM9+OTVI52HWFlML//Tp08nJyaFPnz40adLE/vXee+/ZHzN16lSuuOIKhg4dysUXX0xsbCwfffSRialFXN9P2RvtG/R0CmnBBeFtTU50oo4hzXm2ze3262PWPc9uHRETOYHj+v2LIzqZmEROx2KxMK3DfSRbK5Yc/5yzmce3vGlyqoYnw2ENv5b01B7Tl/Sc7GvUqFH2xwQEBDBt2jSOHDlCfn4+H3300SnX74tIBcej+yMTBpmY5PRuTbySq2MvAiC7LI8Ra57SETGRP3Ccv39J1PkmJpEzCfMN5u0uE/G1+AAwNf09vs5aaXKqhqVqDX+kbyjBmkZVa1zipF0RqT2HS3L4cP9iAEJ8ghjR9DJzA52GxWLhlQ7jSaqcxLAyeyNPbn3L3FAiLsRm2Ow77Ib6BNE1rJW5geSMuoW15qnWt9ivj/71WfYWHTQxUcNRVF7CvqJDAMRbo0xO415U+EXczH/2fEOxrRSAa5v0JtAnwOREpxfmG8zsLhPxsXgD8MLv77Lg4C8mpxJxDb/mbudo5U7Z3cPb4l3590Rc253JQxkUXXGu4ZHSXEateZpyo9zkVK7P8URnjeSsXSr8Im7EZticlvOMTbrGxDTVd0FYG55oNRoAA4O//foMmcVHTE4lYj7HcZy9Tdw4T86OxWJhRscHaBrQGIBlR9czedsck1O5vnSHE3aTrU1MTOJ+VPhF3MiSw2vZXrkb54Vh7WgX0szkRNU3LuXP9vnih0pyuGmtjoiJLDq82n750saav9+QRPqFMrvzo3hbKqrW5O1znc7HkBNpJGfdUeEXcSOv7/rMfvlvia6x0VZ1eVm8eL3jg8T6RwAVv7z8a/t/TU4lYp4SWynLjqwHINovnLaNks0NJGetR0QH/pF6E1Dx6eWotU+TVXzU5FSuK8Nh063mgU1NTOJ+VPhF3MS+okN8fmAZAI39Qvlzk74mJzp7Uf5hzOo8AQsWAJ7c9hY/VhYeEU/zS/ZmCsqLAEgLb4/FYjE5kdTEfc3/Qr/IrgBklRzlb2snYzNsJqdyTY4jOas2Z5TaocIv4iZm7/6K8sp/RK6P64+/t5/JiWqmd2QXHm5xIwA2DEaseYrDJTkmpxKpf4sc5u/3iexsXhA5J14WL2Z2fohov3AAFh5exZTf3zvDd3mmqiU9PhZvTempZSr8Im6gzFbOm7vnAWDBwu0N5GTdU3k4dTgXRXQEYF/xIW5b9zyGYZicSqR+LXEo/JdGa/1+QxbjH+H06eUTW99k+ZENJqdyLYZh2Jf0NA2I0kSqWqbCL+IG5h9caZ/z3CeyS4M/2cnb4s2bnScQ6RsKwJdZy3klQztsi+fILytk5dGNQMV4whTtONrg9W18Hg+2GAZAuWFjxFp9eunocGkux8oKAIgPiDY5jftR4RdxA46jOEcnXmFiktrTNCCK1zs9aL8+YfNrrMreYmIikfqz/OhvlBoVu073CG9vchqpLRNajKBXeMWnl3uLDnLrr8/p08tKGQ4TehIDNYO/tqnwizRwGQX7+fbgz0BFSb4qtpfJiWrPZdHdGZfyZwBKjXJuXPMkuaX5JqcSqXuLHcZx9m3c1cQkUpt8vLyZ1WUCEb4hAHx1cAXT9Okl4Fz4mwVqBn9tU+EXaeDe3DUPg4ojRH9tOsDt1j0+0Wo03UJbAxUj2+7cMEVHxMTtLXKY135p4/NNTCK1rWlAFG90esh+/ZHNr/FL9mYTE7kGpxn8WsJW61T4RRqw4vISZu/5CqiYajAm6WpzA9UBPy9fZnd5hEY+gQB8uH8xb+350uRUInXnaOkx1uZuA6B1cCIxAREmJ5Ladll0d+5pdh1Q9enlJHJK80xOZa6MQo3krEsq/CIN2GcHlnKwJBuAS6MuoEnlNu7uJiUwjukdxtuv3/fbv9l4LMO8QCJ16PvDv9o/tUvT+n239XjL0VwQ1gaAnYUHuH39vzz600vHJT3NVfhrnQq/SAP2usPJurcmDjExSd27tklvbq78MxbZShi2+gn7pkQi7sRxHOeAxt1MTCJ1ydfLh9mdHyXUJxiATzJ/4I1dX5icyjxVS3pCfIII921kchr3o8Iv0kBtOpbB0iPrAGgeGMclUe4/p/ufbW6nfaNmAGzJ38V9v/2fyYlEal/VCbveFi/7Dq3inpICY3m14/326w9smsa63B0mJjJHma2c3UUHAIgP0IZbdUGFX6SBcjwSNDz+MiwWi4lp6ofV2585XSYS6O0PwOw983l/30KTU4nUnv1Fh9mctwuADo2aE+oXbHIiqWtXxfayb5ZYbCtl2OonyCsrNDlV/dpTlGXfKT7BqpGcdUGFX6QByi8r5J293wAQ4OXHzW4ye786WgUnMrXdXfbrY9e/wI78vSYmEqk9jst5ekZ0MDGJ1KdnWt9K55BUAHYU7GXcby+aG6ieOU7oSbbGmpjEfanwizRAH+xfRE5ZxTz6K2J6EOkXanKi+jW86UBuiBsAQH55EcPXTKK4vMTkVCLnbpHW73skf28/5nSZSLC3FYD/7l3A3D1fm5yq/mgkZ91T4RdpgByX89yaeJWJScxhsVh4sf04mgc2BeDX3O08svl1k1OJnBvDMFh8qGL9vp+XLxdHdjY3kNSr5kFNmdbhXvv1cRteYnPeThMT1R/nCT1NTUzivlT4RRqYVdlbWJ2zBYB2jVI89mP/Rj6BzD3vH/h7+QLwys6P+OLAjyanEqm59IL97C7KAqBraCusleeqiOf4c1w/bkq4HIBCWzHDVj9BYXmxyanqXkbh8cKvGfx1Q4VfpIF5w2EU5wgPOVn3VDqFtGBy6zH267f++k92Fx4wMZFIzS12WM5zUURHE5OImZ5vewdtgpMB2JS3k/Ebp5kbqB5ULemxYCEpUGv464IKv0gDkl2aZ59KE+xtZVT8YJMTme+2pKu4MqYXANlleYxc8xRltnKTU4mcvapxnKD1+54s0DuAuV0mYvWq+IRn1u55fODm08iqlvTE+kfgV/mprdQuFX6RBuS/e7+l0Fbx8e7VsRfTyDfQ5ETms1gsTO84nsSAilFuK7I38uS2t8wNJXKWDMNgyeG1AAR5W7lQO+x6tDaNkv8wjWyK204jyy3N53BpLqCRnHVJhV+kgTAMg9d3fWa/fnvS1eaFcTHhvo2Y3eURvC0V/0n7147/svDQKpNTiVTfb8fSOViSDcAFYW3w8fI2N5CY7sb449PI8soL3XYaWUZhpv1yojXaxCTuTYVfpIFYdnS9fUOebqGt6RLW0uRErqV7eDseb/k3AAwMblr7DAeKj5icSqR6HNfv99Z0HuH4NLIWlSex/pq7nQmbZ5icqvY5juRMsWokZ11R4RdpIF7fefzo/qgErd0/mXuaXc+AxucDcLAkm7+tnYytcvdGEVfmWPgviTrfxCTiShr5BDKny0T7NLLpOz/ms8ylJqeqXRkF++yXmwU1MTGJe1PhF2kAsoqP8knmD0DF8pW/Vn7MK868LF680elBYvwjAFh0eDUv7HjX5FQip1dmK2fpkXUARPiG0CmkhcmJxJV0CmnBP9vcYb9+27rn2OVG08gcl/S0CNRIzrqiwi/SALy9Zz6lRhkAf27SlwAfzec+lWj/cGZ1moCFinGlk7bNYvmRDSanEjm11blbya3cOTstvB1eFv3TLM5uSRzCNbEXA5BTls+NqydRaiszOVXtcFzS0yJYhb+u6L8qIi7OZtiY6bCz7u3J15iYpmHo07gLD7YYBkC5YWPE2qc4UpJrciqRk6vaXRegd2QXE5OIq7JYLEzrcB/J1ooZ9T/nbObxLW+anKp2VI3ktHr5E+0XbnIa96XCL+Livj34MzsrP/K8KKITrYITTU7UMExoMYKe4RW7EO8tOsit657DMAyTU4mcqGocJ8DAqAvMCyIuLcw3mLe7TMTX4gPA1PT3+Dprpcmpzo3NsNmX9MRbozx6I8m6psIv4uLecDi6/7fKLdflzHy8vJnV+REifEMA+DJrOdN3fmxyKhFnReUlLD9aseQszr+xfSKLyMl0C2vNU61vsV8f/euz7C06aGKic7O/+DAltlJAM/jrmgq/iAvbXXiAr7JWABDjH8HQJn3MDdTAxFujmNHxAfv1CZteY03OVhMTiThbcfQ3imwVs9V7RLTXEU45ozuThzIo+kIAjpTmMmrN05QbDXN38QyH9ftJlcuVpG6o8Iu4sFm7v8RGxVjJG+IGaDOeGhgck8bfk4cCUGKUMXzNkxwrKzA5lUgFx3GcfbR+X6rBYrEwo+MDNA1oDFTs0TJ52xyTU9WM4wm7zQI1krMuqfCLuKhSWxlv7f4KAG+LF2O0s26NPdn6Fs4LrdioLL1gH3eun6L1/OISFh8+fsKu1u9LdUX6hTK786P23cUnb5/L4kNrzvBdrse58Dc1MYn7U+EXcVHzDvxIZvFhAPo37kpioNY31pSfly9zukykkU8gAB/sX8TsPV+ZnEo8XW5pPqtytgDQPLApTa3RJieShqRHRAf+kXoTULG7+Ki1T5NVfNTkVGdnp8MM/lSdv1KnVPhFXNTruz63X7458UoTk7iHlMA4Xulwn/36vb/9HxuPZZgXSDze0iPrKK/cCTotvL3JaaQhuq/5X+gX2RWArJKjDW53cacj/EFxJiZxfyr8Ii5oW95uFlV+1J9ojWFw5Qlacm6GNuljn3RUZCth+JpJFJQXmZxKPNUSh/X7/Rt3NTGJNFReFi9mdn7Ivrv4wsOrmPL7eyanqr6qwt/YL5RA7wCT07g3FX4RFzRz9/FRnMObDtTOm7Xo+bZjaRucDMDmvJ2M3zjN3EDisapO2LVgYUDjbiankYYqxj+CNzs9bN9d/ImtbzaI3cULy4vty1YTArRkta6pRYi4mMLyYubu+RqoWHt+S9IQkxO5F6u3P3O6TMTq5Q/AW7u/5MN9i0xOJZ4mq/go64/9DkC7RilE+oeanEgasr6Nzzthd/HDJTkmpzo9x/X7CTp/pc6p8Iu4mI/2L+FI6TEABkVdaP+oVmpPm0bJTG13l/36Hetf4Pf8fSYmEk/zw5Ff7Zd7aP2+1IIJLUbQK7wjULm7+K+uvbu44/r9FI3krHMq/CIu5g2Hk3VvTdLJunXlxviB/CWuPwB55YUMXzOJ4vISk1OJp1h06Pg4zgFRWs4j587Hy5tZXSbYdxf/6uAKpmV8ZHKqU8twKvw6YbeuqfCLuJB1uTtYmb0RgFZBidqIpw5ZLBZean83zStnP6/N3cajW143OZV4iiWH1wLga/Gmb+R55oYRt9E0IIo3Oj1kv/7I5tf4JXuziYlOzbHwtwjSDP66psIv4kIcj+7fGD8Qi8ViYhr318gnkDldJuJn8QFgWsZHzDvwo8mpxN3tLjzAjoK9AHQOSSXIx2pyInEnl0V3555m1wFQapRz45pJ5JTmmZzqROmFxwt/aqBm8Nc1FX4RF3GsrIB39y4AINDb3z4+UupW59BUJrcZY79+67rn2FOYZWIicXeLHcZx9oroZGIScVePtxzNBWFtANhZeIDb1//L5dbzVx3h97X4EGdtbHIa96fCL+Ii3t37HXnlhQBcGdOLML9GJifyHGOSrmZITE8AjpYeY+TapyizlZucStzV4kPHC7/W70td8PXyYXbnRwn1CQbgk8wfeGPXF2f4rvpjGIb9pN2mAVF4W7xNTuT+VPhFXIBhGLyx6zP79TFJV5sXxgNZLBamdxhPQkDFaLjlR3/j6W2zTU4l7sgwDBZVHuG3evnTM6KDyYnEXSUFxvJqx/vt1x/YNI11uTtMTHTcoZIc8is3PdRIzvqhwi/iAn7K3mifyd0ppAUXhLc1OZHnifALYXaXR/Gu3OTsuR3vOE1SEakNW/N32zcb6hbWGj8vX5MTiTu7KrYXtyddA0CxrZRhq58gr6zQ5FTO6/cTrdp0qz6o8Iu4gNcdTtYdlTDYxCSe7cLwdjzW8m8AGBiMWvs0B4qPmJxK3InjL5EXa/2+1INnWt9K55BUAHYU7GXchhfNDcQfR3JqBn99UOEXMdnhkhz+t38xAKE+QdzYdKC5gTzcvc2uZ0DjinXVB0uyGb32WWyGzeRU4i6qxnECXBJ1vnlBxGP4e/sxp8tEgr0rpkH9d98C+27uZnEs/FWjkaVuqfCLmGzunq8ptpUCcG2TPgT6BJicyLN5Wbx4vdOD9h2OFx5exZTf3zM5lbiDcqOc74+sBSp+ue8a1srcQOIxmgc1ZVqHe+3Xx214ic15O03L47jLbmqQRnLWBxV+ERPZDBszHSYn3KGTdV1CjH8Eb3Z6GAsV+yA8sfVNVhz9zeRU0tCty93B0dJjQMXyMU0mkfr057h+3FQ57rnQVsyw1U9QWF5sSpYMhzX8zbXpVr1Q4Rcx0eLDa9heuQFPWnh72oU0MzmRVOnb+Dzub/5XAMoNGyPWPMmRklyTU0lD5jh//+LIzuYFEY/1fNs7aBucDMCmvJ2M3zjNlBxVR/hDfYII9Q02JYOnUeGvQ4ZhaO2vnJbjzro36WRdl/No6kh6hLcHYE/RQcase97lNq+RhmORw/z9gY0vMDGJeKpA7wDmdJmI1csfgFm75/HBvoX1mqHUVsaewoMAJGhCT71R4a9D8w+upMey2/niwI8qCXKCfUWH+PzAMgCi/MK4Pq6/yYnkj3y8vHmr8yOE+1ZsgvZF1o+8uvNTk1NJQ1RiK+XHo+sBiPYLp02jZHMDicdq0yiZqe3usl8fu34KO/L31tvr7y7MwkbFwVDN4K8/Kvx1xDAMntz6Futyt3Pdqon0WnYH87NWqviL3Vu7v6S88hOg6+L64evlY3IiOZl4azQzOj5gv/7wpumsydlqYiJpiH7O3kRB5UZDaeHtsVgsJicST3Zj/EBuiBsAQF55IcPXTKK4vKReXju9YJ/9crI1tl5eU1T468zBkmz7CX8Aa3K3cu0vE+iz/O8sOPiLir+HK7OVM2v3lwB4YeGOpGtNTiSnc3lMD+5MHgpAiVHG8DVPcqyswORU0pAsdhjH2Ufr98VkFouFF9uPo0XlhJxfc7czYfOMenltx023UgLj6uU1RYW/zkT7h7O05yu83/VJ2gWn2G//OXsTV/78IANW3M1ih/Wc4lm+OriCvUUVaxh7R3YhJUgbj7i6J1vdTJeQlkDFEaq7NkzVL+5SbYsdNtwaGN3dxCQiFRr5BDKny0T8K3d7nr7zYz7LXFrnr7uzINN+uYVm8NcbFf46ZLFYuCKmBysvmsE75z1O6+Ak+33Lj25g8E/juWzFvSw9ss68kGIKx5N1b04cYmISqa6qzWsaVW5e896+hcwxefMaaRjyywr5KXsTAEnWWJK1s6i4iE4hLfhnmzvs129b9xy7Cg/U6Ws6z+BPqNPXkuNU+OuBl8WLq2Mv4peL3mBOl4lOm0x8f+RXLl1xD1esvF9zvj1EesE+Fhz8BYCmAVFcGdvT5ERSXc2C4vi3w+Y19/z2sqmb10jD8OPRDZQaZQCkhbczOY2Is1sSh3BN7MUA5JTlc+PqSZTayurs9aoKvxcWEgM1pae+qPDXIy+LF0Ob9GH1xW8yq9MEp7VrCw+vpt/yu7jq54f4OXuziSmlrr25ax4GFUtB/tr0Em2+08D8Oa4foypHqJq9eY00DIsPH1/O069xVxOTiJzIYrEwrcN99hNof87ZzONb3qyz16vadKtJQGMNq6hHKvwm8LZ4c33T/vx68Vu81uEBkhzm0H578Gd6/ziWob88okkgbqi4vITZe74CwNfizZikq0xOJDXxr7ZjaeOwec39Jm1eIw3D4kNr7Zcv1fx9cUFhvsG83WUivpaKAj41/T2+zlpZ66+TXZpn3206IUAjOeuTCr+JfLy8uTFhIOt6v80r7e8jPiDKft9XWSvouex2rl/1D9bl7jAxpdSmTw8s5VBJDgCXRl1Ak4DGJieSmgj0DmCuw+Y1b+6ex//2LzY3lLikIyW5rM3dBkDr4ESiA8JNTiRyct3CWvNU61vs10f/+qx9uERtyXBYv5+oTbfqlQq/C/D18mFU4mA29JnDy+3upol/pP2+zw8s48KltzJs9RNsPJZhXkipFa/v/Mx++RadrNugtWmUzAvt7rRfv2PdC07zpUUAfjiyzr6ELy28g8lpRE7vzuShDIq+EIAjpbmMWvM05UZ5rT2/Y+FPDtQM/vqkwu9C/Lx8uTlpCBv7zGVK278T7Xf8SNDHmd9z/g83M3LNU2zJ22ViSqmpjccyWFa502bzwDguidJH+w3dyPhBXNekHwDHygsYvnoSJbZSk1OJK3Fcvz9A6/fFxVksFmZ0fICmlZ8+Lzu6nsnb5tTa82cUHh/J2VwjOeuVCr8L8vf2Y0zy1Wzq+x+ea3MHUX5hABgYfLB/EV2/H83Nvz5br1thy7lzHMU5PP4y7bTpBiwWCy+3v5tmlSfgr8ndxsTNb5icSlzJksMV+614W7zoF6nCL64v0i+U2Z0fxdtSUREnb59ba/sGOY7kbOEwsVDqngq/C7N6+3NnylA29f0PT7e6lQjfEABs2Hhn77d0/n4Ut617XssIGoD8skLe2fstAAFeftyceIXJiaS2hPgGOZ3s9n8ZH/JV1gqTU4kr2Fd0iM2Vn8h2aNScUL9gkxOJVE+PiA78I/UmoOJg46i1T5NVfPScn1eF3zwq/A1AoHcA9zS/ns193+GJlqMJ86n4R6PcsDFnz3w6LRnF2PVT6nyzDKm59/cvJLcsH4ArYnoQ6RdqciKpTeeFtmRym9vs12/+9Vn2FNbuyW7S8FQd3QfoFdHRxCQiZ+++5n+xfyqVVXKUv62djM2wndNzZlQeoAz09qex/h2sVyr8DUiwj5X7W/yVzX3fYWLqKEJ8ggAoM8qZtXseHRaPYNyGl1Q0XNAbO7+wXx6TdLV5QaTO3J50DVfE9ADgaOkxRq59ijJb7Z3sJg3P4sNr7Zf7a/2+NDBeFi9mdn6IGP8IABYeXsWU39+r8fOVG+XsKsoCICEgRsta65kKfwMU4hvEw6k3srnvOzzcYjjB3lYASo0yXt/1GR2W3Mj4jf9mf9Fhk5MKwC/Zm1mTW7GnQrtGKaSFtzc5kdQFi8XCqx3ut4/XXX50A89se9vkVGIWwzBYfKjihF0/L196R3YxOZHI2Yvxj+DNTg9joaKcP7H1TZYf2VCj59pfdNg+1CDBqhn89U2FvwEL8w1mYsub2Nz3He5vfgNB3gEAFNtKeSXjY9otHs5Dm6ZzoPiIyUk9m+PJuiPjB+mohhuL8AtxOtntnzv+U2snu0nDkl6wn92VRzO7hrYiwNvP5EQiNdO38Xk82GIYULGUeMTapzhcuZ/M2XBcv59k1UjO+qbC7wYi/EJ4otXNbOr7DnenXGffDKjIVsLL6R/SbvFwHt08w77hk9Sfo6XH+GDfIgCCva2Mih9kciKpa2kR7ZmYOgqo3ZPdpGFZ5DCO8yKt35cGbkKLEfQKr/j/8d6ig9z663MYhnFWz+FY+FMCm9RqPjkzFX430tgvlGfa3MbGvnO5M3ko/l6+ABSUFzPl9/dou2gYj22ZyZGSXJOTeo7/7v2WQlsxANc0uZhg30CTE0l9GN/8BvpGngdUnOw2+tdzP9lNGhbHE3YvaXy+iUlEzp2PlzezukywTwv86uAKpmV8dFbPkVGoCT1mUuF3QzH+ETzX9g429vkPY5Kuxq+y+OeVF/L8jndou3gYT259i+zSPJOTujfDMJyW89yedI2JaaQ+VZzs9rB9D43vDq3ixd/fNzeU1BubYWNJ5Qm7wd5Wuoe3MzeQSC1oGhDFG50esl9/ZPNr/JK9udrfn+E0klObbtU3FX431iQgkint/s6G3nO4OXEIvhZvAHLLCpi8fQ5tFw3j2e1zyS3NNzmpe1p6ZJ19Bvf5oa3pHJpqciKpT7H+EczqPMF+stvjW99k5dHfTE4l9eG3Y+kcLMkG4ILwtvh4eZsbSKSWXBbdnXuaXQdAqVHOjWsmkVPNg4fOS3ri6iSfnJoKvweIt0bxcvu7Wd9nDqPiB+NTWfyzy/KYtHUWbRcP4187/kteWaHJSd3L67s+s18emTDYxCRiln6NuzK++Q1AxfjcG9c8ydHSYyankrq2xGEc58URncwLIlIHHm85mgvC2gCws/AAt6//V7XW82cUZgIQ7ReO1du/TjPKiVT4PUiiNYZXOt7Hut6zGd70UvskkSOlx/jHljdos2gYL/7+PgXlRSYnbfgOFB/h08ylAIT7NuKvcQNMTiRmmZg6irTKJR17ig4yZt3zZ32ymzQsjifsXhp1gYlJRGqfr5cPszs/SmjlJqCfZP7AG7u+OO33FJQX2ScGaiSnOVT4PVByYBNmdHqQNRfP4vq4/nhVLjk4XJrDhM2v0XbRcP6d/j8Ky4tNTtpwvb17PqVGGQB/btKXAB8dzfBUPl7evNX5EcJ8K/5x/PzAMl7b+anJqaSulNnKWXpkHQARviF0DGluciKR2pcUGMurHe+3X39g0zTW5e445eMzCjLtl1X4zaHC78FaBMUzq/MEVl38JkNj+9jXGmeVHOWBTa/QbvGNTM/4hOLyEpOTNizlRjlv7p5nv35H8rUmphFXkGCNYUbHB+3XH9o0nV9zt5uYSOrK6pwtHCsrACAtvB1eFv0zK+7pqthe9mEUxbZShq1+4pRLg9ML9tkvJ1s1ktMM+i+R0Co4kTnnTeTni97gqpiL7LdnFh/mvo3/R/slI3h95+f2HfLk9L49+As7K9cqXhTRiZbBCSYnEldwRUwP7kiu+MexxChj+OpJOm/GDS12GMfZp3I0q4i7eqb1rXQOqRhIsaNgL+M2vHjSx1X9mwjQLFATesygwi92bRsl89+uj7Oy1wyuiO5hv31v0UHG/fYiHZeM5K3dX1JqKzMxpetzHMU5OuFyE5OIq3m6lfM/jndtmKr1/G7GsfBfGqX5++Le/L39mNNlIsHeVgD+u28Bc/d8fcLj0jWS03SmFv7vv/+eIUOGEBcXh8Vi4ZNPPnG63zAM/vGPf9CkSROsVisDBgxg27Zt5oT1IB1CmvN+tydZ1nM6l0V1t9++q/AAd6x/gc5LRjF3z9eU2cpNTOmadhceYH7WSgBi/SO5tkkfcwOJS/njP47v7vuOuXtP/MdRGqbC8mKWH90AVMws1+ZC4gmaBzVlWod77dfHbXiJzXk7nR7jWPhTg/X3wgymFv78/Hw6derEtGnTTnr/c889x8svv8yrr77KypUrCQoKYuDAgRQVaYpMfegS2pKPzn+GJT2mMaBxN/vt6YX7uXXdc5z3/U28u3cB5YaKf5U3d3+JjYodVW+I66/523KC5kFN+bfDP453b3j5hH8cpWFaeXQjxZVLH9PC22GxWExOJFI//hzXj5sqP9EutBUzbPUTToM/qjbd8vPypYl/pCkZPZ2phX/QoEE89dRTXHPNiTuQGobBiy++yKOPPspVV11Fx44defvtt9m3b98JnwRI3To/rDWfXfBPFqa9TO+Izvbbtxfs5W+/Tqbb9zfz4b5F2AybeSFdQKmtjLd2fwmAt8WL25KuNjeQuKzr4voxMn4QUPGP4/DVkzQVyw04juPsq/X74mGeb3sHbYOTAdiUt5PxGysO5hqGYZ/BHx8QpRPZTeKyP/X09HQyMzMZMOD4/PLQ0FC6d+/O8uXLT/l9xcXF5ObmOn1J7bgwvB1fXfgC31w4lR7h7e23b8nfxYi1T9H9h1v5ZP/3Hlv8vziwzD5neEDjbiQGxpicSFzZC+3upHVwEgAb8zJ4YOMrJieSc7VE6/fFgwV6BzCny0QCKzfVmrV7Hh/sW0hWyVH7/j4ayWkely38mZkVvw3GxDiXppiYGPt9JzN58mRCQ0PtXwkJmpBS23pFdGRB2kt81f1fXBDW1n77b3np/HXNE/RYdjtfHPjR405GfN3xZN3EISYmkYag6h/HAC8/AGbu/oKP9i8xOZXUVG5pPqtytgDQPLApTVVsxAO1aZTMlLZ32a+PXT+F7w6tsl9PCNCBMLP4mB2gtj388MPce+/x9bG5ubkq/XWkd2QXFqW9zMJDq3hs65usrvzHbl3udq5bNZEuIS2Z2HIUA6MucPu1rFvzdtuncyRZYxkcfaHJiaQhaNcohX+1vZM7N0wB4Pb1/+K80JYkB7r+nOpSWxmF5cUU2IopKi+msLyYQlsJheVFFJaXUFh5u6+XL8HeVoJ9rAR5B1T+b8V1q5e/2/y3YemRdZRXfrrZI6KDyWlEzHNj/ECWHF7Df/ctIK+8kDvXT7Hf1ywwzsRkns1lC39sbCwABw4coEmT4//4HThwgM6dO5/y+/z9/fH3166m9cVisdA/qhv9Gnflm4M/8fjWN+0bCq3J3cq1v0zg/LA2TEwdRf/GXd3mH/c/mulwdH9Y00u1RlGq7aaEwSw+vJoP9y/mWFkBN655ku/SXsLPy/esnsdm2E5augvLj38V2UooqLyvqPK+gvLiysslld9f+djK5yooL6LIocAXVD6mvBaW7lmwEOxjJdA7gGBvK0E+VoK9Ayr/9/gvBie9r/IXiCD7LxPHH2vGyfKO4zj7af2+eDCLxcKL7cfxc85mtufvoch2fPPO5kEq/GZx2cKfkpJCbGws3333nb3g5+bmsnLlSm6//XZzw8kJLBYLA6O7c2nUBczLWs4TW97kt7x0AH7O3sSVPz9IWnh7JqaOok/jLianrV2F5cXM3fsNUDGB4JYkLeeR6rNYLPy7/b2sztnK7wX7WJWzhb+seozkwCanLOnHi3lJRQm3FTfIjfEMDI6VFXCsrIADtfi8/pWfKgQ5/bJgJcin4heEP37S4PS/p7gvwMvvtAcsFleesGvBwiVavy8erpFPIHO6TKTPj3faJ1cBpGpUrWlMLfx5eXls3358e/n09HTWrl1LREQEiYmJ3H333Tz11FOkpqaSkpLCxIkTiYuL4+qrrzYvtJyWxWLhipgeDI6+kM8OLGPS1ln2kYPLj25g8E/juTiiE4+2HEWviI4mp60d/9u/mKOlxwAYFHUhMf4RJieShibEN4jZnR+l3/K7KDXKmH9wpdmR7Hws3vh7+RHg5YfV26/isnfF9QAvf/tlq7cfVq+Aiv/19q/48vKnzCgnr6yAvPJC8sqLyC8rJL+8kPyyIgrKi8gvr/jfqq/SWhjzW2wrpdhWyuHS2hva4IWX/ReGk33SsOFYxQGOdo1SiPALqbXXFWmoOoW04J9t7uDu316y36Zdds1jauH/5Zdf6Nu3r/161dr7kSNH8tZbb/HAAw+Qn5/PrbfeSnZ2Nr169WL+/PkEBASYFVmqycvixdWxF3FlTE8+zvyeSVtnsS1/DwDfH/mVS1fcw4Xh7dxiHu/P2Zvtl8ckXWViEmnIuoa14p9tbufejf932sdZsFSU7cryba0s3MdLuT/+Xr5Yvf0J8PInsKp8VxbwQO+KUh7oHVD5VXFbkHcAgT4BWCtLvNWr4nt8ver3n4kSWyn5lb8Y5JUXkldWyLGyAvLKCsgtK6i4Xl5w/JeIskIKyovIKyt0+uXB+ReJcx95asNm/zTidHpq/b6I3S2JQ/glexNz935Dz/COhPgGmR3JY1kMNx+lkpubS2hoKDk5OYSE6KiLWcqNcj7ct5hJ294ivWCf2XHqRKugRFZf/Kbbnqcg9WND7u8cLsnBWlnEA70DKgp4ZWH39/LV/8fOks2wUVBeTF554fFfJEorfmHIrfxl4pjDLxB5lY/Jr3y88y8SxRRW/kJR9odPIwK8/FiU9n90Cm1h0p9UxPUYhsGW/F2kWJvg7+1ndhy3cjYdV4Vf6lWZrZx39y3g6W1vs7Pw1ONVGxpfizczOj7I9U37mx1FROpJia208pOFQo6VFZJgjaaRT6DZsUTEQ6jwO1Dhd02GYbC/+DA2N/m/X5hvMME+VrNjiIiIiIc4m47rslN6xL1ZLBbiAhqbHUNERETE7WlYuIiIiIiIG1PhFxERERFxYyr8IiIiIiJuTIVfRERERMSNqfCLiIiIiLgxFX4RERERETemwi8iIiIi4sZU+EVERERE3JgKv4iIiIiIG1PhFxERERFxYyr8IiIiIiJuTIVfRERERMSNqfCLiIiIiLgxFX4RERERETemwi8iIiIi4sZU+EVERERE3JgKv4iIiIiIG/MxO0BdMwwDgNzcXJOTiIiIiIjUjqpuW9V1T8ftC/+xY8cASEhIMDmJiIiIiEjtOnbsGKGhoad9jMWozq8FDZjNZmPfvn00atQIi8VidhyPlpubS0JCArt37yYkJMTsOPIHen9cm94f16b3x7Xp/XFten9qxjAMjh07RlxcHF5ep1+l7/ZH+L28vIiPjzc7hjgICQnRX2gXpvfHten9cW16f1yb3h/Xpvfn7J3pyH4VnbQrIiIiIuLGVPhFRERERNyYCr/UG39/fx577DH8/f3NjiInoffHten9cW16f1yb3h/Xpven7rn9SbsiIiIiIp5MR/hFRERERNyYCr+IiIiIiBtT4RcRERERcWMq/CIiIiIibkyFX85o8uTJnH/++TRq1Ijo6GiuvvpqtmzZ4vSYoqIixo4dS2RkJMHBwQwdOpQDBw44PWbXrl1cfvnlBAYGEh0dzf33309ZWdlpX/vIkSMMGzaMkJAQwsLCGD16NHl5ebX+Z2zIpk+fTseOHe0blqSlpfHVV1/Z79d741qeffZZLBYLd999t/02vUfmefzxx7FYLE5frVu3tt+v98Z8e/fuZfjw4URGRmK1WunQoQO//PKL/X7DMPjHP/5BkyZNsFqtDBgwgG3btjk9R01+3tV57z1dcnLyCX9/LBYLY8eOBfT3x6UYImcwcOBAY9asWcaGDRuMtWvXGoMHDzYSExONvLw8+2PGjBljJCQkGN99953xyy+/GBdeeKHRo0cP+/1lZWVG+/btjQEDBhhr1qwxvvzyS6Nx48bGww8/fNrXvuyyy4xOnToZK1asMH744QejRYsWxg033FBnf9aG6LPPPjPmzZtnbN261diyZYsxYcIEw9fX19iwYYNhGHpvXMlPP/1kJCcnGx07djTGjRtnv13vkXkee+wxo127dsb+/fvtXwcPHrTfr/fGXEeOHDGSkpKMUaNGGStXrjR+//134+uvvza2b99uf8yzzz5rhIaGGp988onx66+/GldeeaWRkpJiFBYW2h9Tk5/3md57MYysrCynvzvffvutARiLFi0yDEN/f1yJCr+ctaysLAMwlixZYhiGYWRnZxu+vr7GBx98YH/Mpk2bDMBYvny5YRiG8eWXXxpeXl5GZmam/THTp083QkJCjOLi4pO+zsaNGw3A+Pnnn+23ffXVV4bFYjH27t1bF380txEeHm688cYbem9cyLFjx4zU1FTj22+/NXr37m0v/HqPzPXYY48ZnTp1Oul9em/M9+CDDxq9evU65f02m82IjY01nn/+eftt2dnZhr+/v/Hf//7XMIya/byr897LicaNG2c0b97csNls+vvjYrSkR85aTk4OABEREQCsWrWK0tJSBgwYYH9M69atSUxMZPny5QAsX76cDh06EBMTY3/MwIEDyc3N5bfffjvp6yxfvpywsDC6detmv23AgAF4eXmxcuXKWv9zuYPy8nLeffdd8vPzSUtL03vjQsaOHcvll1/u9F6A/v64gm3bthEXF0ezZs0YNmwYu3btAvTeuILPPvuMbt268ec//5no6Gi6dOnC66+/br8/PT2dzMxMp/coNDSU7t27O71HZ/vzrs57L85KSkqYO3cuf/vb37BYLPr742JU+OWs2Gw27r77bnr27En79u0ByMzMxM/Pj7CwMKfHxsTEkJmZaX+M41/oqvur7juZzMxMoqOjnW7z8fEhIiLilN/jqdavX09wcDD+/v6MGTOGjz/+mLZt2+q9cRHvvvsuq1evZvLkySfcp/fIXN27d+ett95i/vz5TJ8+nfT0dC666CKOHTum98YF/P7770yfPp3U1FS+/vprbr/9du666y5mz54NHP8Zn+w9cHyPzvbnXZ33Xpx98sknZGdnM2rUKED/bXM1PmYHkIZl7NixbNiwgaVLl5odRRy0atWKtWvXkpOTw4cffsjIkSNZsmSJ2bEE2L17N+PGjePbb78lICDA7DjyB4MGDbJf7tixI927dycpKYn3338fq9VqYjKBioNM3bp145lnngGgS5cubNiwgVdffZWRI0eanE4czZw5k0GDBhEXF2d2FDkJHeGXarvzzjv54osvWLRoEfHx8fbbY2NjKSkpITs72+nxBw4cIDY21v6YP56ZX3W96jF/FBsbS1ZWltNtZWVlHDly5JTf46n8/Pxo0aIFXbt2ZfLkyXTq1ImXXnpJ740LWLVqFVlZWZx33nn4+Pjg4+PDkiVLePnll/Hx8SEmJkbvkQsJCwujZcuWbN++XX9/XECTJk1o27at021t2rSxL7uq+nmd7D1wfI/O9uddnfdejtu5cycLFizg5ptvtt+mvz+uRYVfzsgwDO68804+/vhjFi5cSEpKitP9Xbt2xdfXl++++85+25YtW9i1axdpaWkApKWlsX79eqe/pN9++y0hISEn/Me8SlpaGtnZ2axatcp+28KFC7HZbHTv3r02/4hux2azUVxcrPfGBfTv35/169ezdu1a+1e3bt0YNmyY/bLeI9eRl5fHjh07aNKkif7+uICePXueMAZ669atJCUlAZCSkkJsbKzTe5Sbm8vKlSud3qOz/XlX572X42bNmkV0dDSXX365/Tb9/XExZp81LK7v9ttvN0JDQ43Fixc7jd8qKCiwP2bMmDFGYmKisXDhQuOXX34x0tLSjLS0NPv9VaO3Lr30UmPt2rXG/PnzjaioKKfRWytXrjRatWpl7Nmzx37bZZddZnTp0sVYuXKlsXTpUiM1NVWjt/7goYceMpYsWWKkp6cb69atMx566CHDYrEY33zzjWEYem9ckeOUHsPQe2Sm++67z1i8eLGRnp5uLFu2zBgwYIDRuHFjIysryzAMvTdm++mnnwwfHx/j6aefNrZt22b85z//MQIDA425c+faH/Pss88aYWFhxqeffmqsW7fOuOqqq046lvN0P+89e/YYrVq1MlauXGm/7UzvvVQoLy83EhMTjQcffPCE+/T3x3Wo8MsZASf9mjVrlv0xhYWFxh133GGEh4cbgYGBxjXXXGPs37/f6XkyMjKMQYMGGVar1WjcuLFx3333GaWlpfb7Fy1aZABGenq6/bbDhw8bN9xwgxEcHGyEhIQYN910k3Hs2LG6/iM3KH/729+MpKQkw8/Pz4iKijL69+9vL/uGoffGFf2x8Os9Ms/1119vNGnSxPDz8zOaNm1qXH/99U4z3vXemO/zzz832rdvb/j7+xutW7c2ZsyY4XS/zWYzJk6caMTExBj+/v5G//79jS1btjg95kw/7/T0dKf58YZRvfdeDOPrr782gBN+5oahvz+uxGIYhmHKRwsiIiIiIlLntIZfRERERMSNqfCLiIiIiLgxFX4RERERETemwi8iIiIi4sZU+EVERERE3JgKv4iIiIiIG1PhFxERERFxYyr8IiIiIiJuTIVfRMSNLV68GIvFQnZ2ttlRRETEJCr8IiJupE+fPtx999326z169GD//v2Ehoaalkm/dIiImMvH7AAiIlJ3/Pz8iI2NNTuGiIiYSEf4RUTcxKhRo1iyZAkvvfQSFosFi8XCW2+95XR0/a233iIsLIwvvviCVq1aERgYyJ/+9CcKCgqYPXs2ycnJhIeHc9ddd1FeXm5/7uLiYsaPH0/Tpk0JCgqie/fuLF682H7/zp07GTJkCOHh4QQFBdGuXTu+/PJLMjIy6Nu3LwDh4eFYLBZGjRoFgM1mY/LkyaSkpGC1WunUqRMffvih/TmrPhmYN28eHTt2JCAggAsvvJANGzac8XVFROQ4HeEXEXETL730Elu3bqV9+/ZMmjQJgN9+++2ExxUUFPDyyy/z7rvvcuzYMa699lquueYawsLC+PLLL/n9998ZOnQoPXv25PrrrwfgzjvvZOPGjbz77rvExcXx8ccfc9lll7F+/XpSU1MZO3YsJSUlfP/99wQFBbFx40aCg4NJSEjgf//7H0OHDmXLli2EhIRgtVoBmDx5MnPnzuXVV18lNTWV77//nuHDhxMVFUXv3r3tee+//35eeuklYmNjmTBhAkOGDGHr1q34+vqe8nVFROQ4FX4RETcRGhqKn58fgYGB9mU8mzdvPuFxpaWlTJ8+nebNmwPwpz/9iTlz5nDgwAGCg4Np27Ytffv2ZdGiRVx//fXs2rWLWbNmsWvXLuLi4gAYP3488+fPZ9asWTzzzDPs2rWLoUOH0qFDBwCaNWtmf72IiAgAoqOjCQsLAyo+MXjmmWdYsGABaWlp9u9ZunQpr732mlPhf+yxx7jkkksAmD17NvHx8Xz88cdcd911p31dERGpoMIvIuJhAgMD7WUfICYmhuTkZKcj4zExMWRlZQGwfv16ysvLadmypdPzFBcXExkZCcBdd93F7bffzjfffMOAAQMYOnQoHTt2PGWG7du3U1BQYC/yVUpKSujSpYvTbVW/EEDFLw+tWrVi06ZNNXpdERFPpMIvIuJhfH19na5bLJaT3maz2QDIy8vD29ubVatW4e3t7fS4ql8Sbr75ZgYOHMi8efP45ptvmDx5Mi+88AJ///vfT5ohLy8PgHnz5tG0aVOn+/z9/av9Zznb1xUR8UQ6aVdExI34+fk5nWxbG7p06UJ5eTlZWVm0aNHC6ctxAlBCQgJjxozho48+4r777uP111+3ZwKccrVt2xZ/f3927dp1wnMmJCQ4vf6KFSvsl48ePcrWrVtp06bNGV9XREQq6Ai/iIgbSU5OZuXKlWRkZBAcHGw/Sn8uWrZsybBhwxgxYgQvvPACXbp04eDBg3z33Xd07NiRyy+/nLvvvptBgwbRsmVLjh49yqJFi+ylPCkpCYvFwhdffMHgwYOxWq00atSI8ePHc88992Cz2ejVqxc5OTksW7aMkJAQRo4caX/9SZMmERkZSUxMDI888giNGzfm6quvBjjt64qISAUd4RcRcSPjx4/H29ubtm3bEhUVxa5du2rleWfNmsWIESO47777aNWqFVdffTU///wziYmJQMXR+7Fjx9KmTRsuu+wyWrZsySuvvAJA06ZNeeKJJ3jooYeIiYnhzjvvBODJJ59k4sSJTJ482f598+bNIyUlxem1n332WcaNG0fXrl3JzMzk888/d/rU4FSvKyIiFSyGYRhmhxAREfmjxYsX07dvX44ePWqf7iMiImdPR/hFRERERNyYCr+IiIiIiBvTkh4RERERETemI/wiIiIiIm5MhV9ERERExI2p8IuIiIiIuDEVfhERERERN6bCLyIiIiLixlT4RURERETcmAq/iIiIiIgbU+EXEREREXFj/w/HTOjSTiLBLQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}