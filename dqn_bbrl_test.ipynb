{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LZXcFYSBs550",
        "hMJF8ZpbyLt0",
        "1WTM15ZG3QcF",
        "kNMqVXUxg9pQ",
        "Ndj4MZ4-hARb",
        "B85LDE9lhEVj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations/Préparations"
      ],
      "metadata": {
        "id": "pVXOYNmls5Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install"
      ],
      "metadata": {
        "id": "LZXcFYSBs550"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMZrJSJHsd0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92686ab4-1906-4b2d-d246-26f053a736cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/dist-packages (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata==4.13.0) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/osigaud/bbrl\n",
            "  Cloning https://github.com/osigaud/bbrl to /tmp/pip-req-build-k6vbjj6j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/osigaud/bbrl /tmp/pip-req-build-k6vbjj6j\n",
            "  Resolved https://github.com/osigaud/bbrl to commit cb2c22b82bfedfb04d8232ba432cdbd798fd797a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install importlib-metadata==4.13.0\n",
        "#!pip install setuptools==65.5.0\n",
        "#!pip install git+https://github.com/osigaud/bbrl_gym\n",
        "!pip install git+https://github.com/osigaud/bbrl\n",
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "hMJF8ZpbyLt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bbrl.workspace import Workspace\n",
        "from bbrl import get_class, get_arguments, instantiate_class\n",
        "\n",
        "#import bbrl_gym\n",
        "import gym\n",
        "\n",
        "from bbrl.agents.agent import Agent\n",
        "from bbrl.agents import Agents, TemporalAgent, PrintAgent\n",
        "from bbrl.agents.gymb import NoAutoResetGymAgent\n",
        "\n",
        "from bbrl.utils.replay_buffer import ReplayBuffer\n",
        "from bbrl.utils.chrono import Chrono\n",
        "\n",
        "from bbrl.visu.visu_policies import plot_policy\n",
        "from bbrl.visu.visu_critics import plot_critic\n",
        "from bbrl.visu.common import final_show\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import os\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import copy"
      ],
      "metadata": {
        "id": "P5EkdUXfslay"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "j62FTCRNyOhn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentés tels quels"
      ],
      "metadata": {
        "id": "1WTM15ZG3QcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "    def __init__(self, cfg):\n",
        "        self.logger = instantiate_class(cfg.logger)\n",
        "\n",
        "    def add_log(self, log_string, loss, epoch):\n",
        "        self.logger.add_scalar(log_string, loss.item(), epoch)\n",
        "\n",
        "    # Log losses\n",
        "    def log_losses(self, epoch, critic_loss, entropy_loss, actor_loss):\n",
        "        self.add_log(\"critic_loss\", critic_loss, epoch)\n",
        "        self.add_log(\"entropy_loss\", entropy_loss, epoch)\n",
        "        self.add_log(\"actor_loss\", actor_loss, epoch)\n",
        "\n",
        "    def log_reward_losses(self, rewards, nb_steps):\n",
        "        self.add_log(\"reward/mean\", rewards.mean(), nb_steps)\n",
        "        self.add_log(\"reward/max\", rewards.max(), nb_steps)\n",
        "        self.add_log(\"reward/min\", rewards.min(), nb_steps)\n",
        "        self.add_log(\"reward/median\", rewards.median(), nb_steps)\n",
        "\n",
        "def format_num(num, pos):\n",
        "    # Pos is a required parameter, but it is not used\n",
        "    magnitude = 0\n",
        "    labels = [\"\", \"K\", \"M\", \"G\"]\n",
        "    while abs(num) >= 1e3:\n",
        "        magnitude += 1\n",
        "        num /= 1e3\n",
        "\n",
        "    return f\"{num:.1f}{labels[magnitude]}\"\n",
        "\n",
        "class Plotter:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def plot_reward(\n",
        "        self,\n",
        "        algo_name,\n",
        "        env_name,\n",
        "        mode=\"mean\",\n",
        "        prefix=\"\",\n",
        "        suffix=\".pdf\",\n",
        "        save_fig=True,\n",
        "        save_dir=\"./plots/\",\n",
        "    ):\n",
        "        _, ax = plt.subplots(figsize=(9, 6))\n",
        "        formatter = FuncFormatter(format_num)\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        color = colors[0]\n",
        "\n",
        "        loader = RewardLoader(self.steps_filename, self.rewards_filename)\n",
        "        steps, rewards = loader.load()\n",
        "        print(steps, rewards)\n",
        "        # steps, rewards = equalize_lengths(steps, rewards)\n",
        "\n",
        "        if mode == \"best\":\n",
        "            best = rewards.sum(axis=1).argmax()\n",
        "            mean = rewards[best]\n",
        "        elif mode == \"max\":\n",
        "            mean = np.max(rewards, axis=0)\n",
        "        else:\n",
        "            std = rewards.std(axis=0)\n",
        "            mean = rewards.mean(axis=0)\n",
        "            ax.fill_between(steps, mean + std, mean - std, alpha=0.1, color=color)\n",
        "        ax.plot(steps, mean, lw=2, label=f\"{algo_name}\", color=color)\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "        plt.legend()\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        figure_name = f\"{prefix}{clean_env_name.lower()}_{mode}\"\n",
        "        title = f\"{clean_env_name} ({mode})\"\n",
        "        if suffix:\n",
        "            figure_name += f\"{suffix}\"\n",
        "        final_show(save_fig, True, save_dir, figure_name, \"timesteps\", \"rewards\", title)\n",
        "\n",
        "    def plot_histograms(\n",
        "        self,\n",
        "        rewards,\n",
        "        env_name,\n",
        "        suffix=\"\",\n",
        "        save_dir=\"./plots/\",\n",
        "        plot=True,\n",
        "        save_fig=True,\n",
        "    ):\n",
        "        plt.figure(figsize=(9, 6))\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        # colors = [\"#fc4f30\", \"#008fd5\", \"#e5ae38\"]\n",
        "\n",
        "        n_bars = len(rewards)\n",
        "        x = np.arange(len(list(rewards.values())[0]))\n",
        "        width = 0.75 / n_bars\n",
        "\n",
        "        for i, reward in enumerate(rewards.values()):\n",
        "            plt.bar(x + width * i, np.sort(reward)[::-1], width=width, color=colors[i])\n",
        "\n",
        "        plt.legend(labels=rewards.keys())\n",
        "        plt.xticks([], [])\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        title = clean_env_name\n",
        "        figure_name = f\"{clean_env_name.lower()}-histograms\"\n",
        "\n",
        "        if suffix:\n",
        "            title += f\" ({suffix})\"\n",
        "            figure_name += f\"{suffix}\"\n",
        "\n",
        "        final_show(save_fig, plot, save_dir, figure_name, \"\", \"rewards\", title)\n",
        "\n",
        "class RewardLogger:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "        self.episode = 0\n",
        "        self.all_rewards = []\n",
        "        self.all_rewards.append([])\n",
        "        self.all_steps = []\n",
        "\n",
        "    def add(self, nb_steps, reward):\n",
        "        if self.episode == 0:\n",
        "            self.all_steps.append(nb_steps)\n",
        "        self.all_rewards[self.episode].append(reward.item())\n",
        "\n",
        "    def new_episode(self):\n",
        "        self.episode += 1\n",
        "        self.all_rewards.append([])\n",
        "\n",
        "    def save(self):\n",
        "        # print(\"reward loader save:\", self.all_steps,  self.all_rewards)\n",
        "        with open(self.steps_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_steps)\n",
        "        with open(self.rewards_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_rewards)\n",
        "\n",
        "class RewardLoader:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def load(self):\n",
        "        with open(self.steps_filename, \"rb\") as f:\n",
        "            steps = np.load(f, allow_pickle=True)\n",
        "        with open(self.rewards_filename, \"rb\") as f:\n",
        "            rewards = np.load(f, allow_pickle=True)\n",
        "        return steps, rewards"
      ],
      "metadata": {
        "id": "Uvi68vi0aE7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d45f64-e4f6-4f64-8246-10667629929d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(sizes, activation, output_activation=nn.Identity()):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        act = activation if j < len(sizes) - 2 else output_activation\n",
        "        layers += [nn.Linear(sizes[j], sizes[j + 1]), act]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def build_alt_mlp(sizes, activation):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        if j < len(sizes) - 2:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1]), activation]\n",
        "        else:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1])]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class DiscreteQAgent(Agent):\n",
        "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
        "        super().__init__()\n",
        "        self.is_q_function = True\n",
        "        self.model = build_alt_mlp(\n",
        "            [state_dim] + list(hidden_layers) + [action_dim], activation=nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, t, choose_action=True, **kwargs):\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        self.set((\"q_values\", t), q_values)\n",
        "        if choose_action:\n",
        "            action = q_values.argmax(-1)\n",
        "            self.set((\"action\", t), action)\n",
        "\n",
        "    def predict_action(self, obs, stochastic):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        if stochastic:\n",
        "            probs = torch.softmax(q_values, dim=-1)\n",
        "            action = torch.distributions.Categorical(probs).sample()\n",
        "        else:\n",
        "            action = q_values.argmax(-1)\n",
        "        return action\n",
        "\n",
        "    def predict_value(self, obs, action):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        return q_values[action[0].int()]\n",
        "\n",
        "\n",
        "class ContinuousQAgent(Agent):\n",
        "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
        "        super().__init__()\n",
        "        self.is_q_function = True\n",
        "        self.model = build_mlp(\n",
        "            [state_dim + action_dim] + list(hidden_layers) + [1], activation=nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, t, detach_actions=False):\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        action = self.get((\"action\", t))\n",
        "        if detach_actions:\n",
        "            action = action.detach()\n",
        "        osb_act = torch.cat((obs, action), dim=1)\n",
        "        q_value = self.model(osb_act)\n",
        "        self.set((\"q_value\", t), q_value)\n",
        "\n",
        "    def predict_value(self, obs, action):\n",
        "        obs_act = torch.cat((obs, action), dim=0)\n",
        "        q_value = self.model(obs_act)\n",
        "        return q_value\n",
        "\n",
        "\n",
        "def make_gym_env(env_name):\n",
        "    return gym.make(env_name)\n",
        "\n",
        "\n",
        "class EGreedyActionSelector(Agent):\n",
        "    def __init__(self, epsilon):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        q_values = self.get((\"q_values\", t))\n",
        "        nb_actions = q_values.size()[1]\n",
        "        size = q_values.size()[0]\n",
        "        is_random = torch.rand(size).lt(self.epsilon).float()\n",
        "        random_action = torch.randint(low=0, high=nb_actions, size=(size,))\n",
        "        max_action = q_values.max(1)[1]\n",
        "        action = is_random * random_action + (1 - is_random) * max_action\n",
        "        action = action.long()\n",
        "        self.set((\"action\", t), action)"
      ],
      "metadata": {
        "id": "qV_L1P7H2ZdY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentés par nous"
      ],
      "metadata": {
        "id": "ppvuEIU13vFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CartWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(CartWrapper, self).__init__(env)\n",
        "\n",
        "        # choix arbitraire d'un goal de départ\n",
        "        pos = random.uniform(-2.4, 2.4)\n",
        "        vel = random.uniform(-1e8, 1e8)\n",
        "        angle = random.uniform(-.2095, .2095)\n",
        "        angle_vel = random.uniform(-1e8, 1e8)\n",
        "        self.goal = (pos, vel, angle, angle_vel)\n",
        "\n",
        "        # distance acceptable autour du but\n",
        "        self.eps = 0.01\n",
        "\n",
        "    def step(self, action):\n",
        "        # effectue un step de l'env CartPole\n",
        "        next_state, _, _, info = self.env.step(action)\n",
        "\n",
        "        # calcul de distance entre next_state et le but\n",
        "        distance = np.linalg.norm(next_state - self.goal)\n",
        "\n",
        "        # récompense et fin si distance inférieure à eps\n",
        "        if distance < self.eps:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return next_state, reward, done, info\n",
        "\n",
        "\n",
        "class GoalRelabellingAgent(Agent):\n",
        "    def __init__(self, env: CartWrapper):\n",
        "        super().__init__()\n",
        "        self.env = env # ?\n",
        "\n",
        "    def change_goal(self):\n",
        "        # modification du but\n",
        "        new_goal = self.choice_goal()\n",
        "        self.env.goal = new_goal\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "PpPmz_8R97pf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "1v6XjQd9zKmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARAMS"
      ],
      "metadata": {
        "id": "kNMqVXUxg9pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params={\n",
        "  \"save_best\": False,\n",
        "  \"plot_agents\": True,\n",
        "  \n",
        "  \"logger\":{\n",
        "    \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
        "    \"log_dir\": \"./dqn_logs/\",\n",
        "    \"cache_size\": 10000,\n",
        "    \"every_n_seconds\": 1,\n",
        "    \"verbose\": False,    \n",
        "  },\n",
        "\n",
        "  \"algorithm\":{\n",
        "    \"seed\": 3,\n",
        "    \"nb_seeds\": 1,\n",
        "\n",
        "    \"epsilon\": 0.1,                 # valeur pour epsilon-greedy\n",
        "    \"discount_factor\": 0.99,        # delta\n",
        "    \"gae\": 0.8,                     # ???\n",
        "\n",
        "    \"n_steps\": 64,                  # nb max de step par épisode ?\n",
        "    \"n_envs\": 50,                    # nb d'environnement en simultané (nb d'épisodes)\n",
        "    \"nb_evals\": 10,                 # nb d'évaluation après train\n",
        "    \"eval_interval\": 10,            # intervalle (steps) entre évaluations ?\n",
        "    \"target_critic_update\": 5,    # intervalle (steps) entre chaque maj de Q_target ?\n",
        "\n",
        "    \"learning_starts\": 1,           # ???\n",
        "\n",
        "    \"n_updates\": 10,                # nb d'update par le Replay Buffer\n",
        "    \"buffer_size\": 1e6,             # taille max du Replay Buffer\n",
        "    \"batch_size\": 50,              # taille du batch Replay Buffer\n",
        "\n",
        "    \"max_grad_norm\": 0.5,           # ???\n",
        "    \"architecture\":{\"hidden_size\": [128, 128]},\n",
        "  },\n",
        "\n",
        "  \"gym_env\":{\n",
        "    \"classname\": \"__main__.make_gym_env\",\n",
        "    \"env_name\": \"CartPole-v1\"\n",
        "  },\n",
        "\n",
        "  \"optimizer\":{\n",
        "    \"classname\": \"torch.optim.Adam\",\n",
        "    \"lr\": 2.3e-3,\n",
        "  }\n",
        "}\n",
        "\n",
        "config = OmegaConf.create(params)"
      ],
      "metadata": {
        "id": "wyiQEOfXzLz7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SET-UP"
      ],
      "metadata": {
        "id": "Ndj4MZ4-hARb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_env_agents(cfg):\n",
        "    train_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.n_envs,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    # print_agent = PrintAgent()\n",
        "    eval_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.nb_evals,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    return train_env_agent, eval_env_agent\n",
        "\n",
        "\n",
        "def create_dqn_agent(cfg, train_env_agent, eval_env_agent):\n",
        "    obs_size, act_size = train_env_agent.get_obs_and_actions_sizes()\n",
        "\n",
        "    critic = DiscreteQAgent(obs_size, cfg.algorithm.architecture.hidden_size, act_size)\n",
        "    explorer = EGreedyActionSelector(cfg.algorithm.epsilon)\n",
        "    target_critic = copy.deepcopy(critic)\n",
        "\n",
        "    q_agent = TemporalAgent(critic)\n",
        "    target_q_agent = TemporalAgent(target_critic)\n",
        "    \n",
        "    tr_agent = Agents(train_env_agent, critic, explorer)\n",
        "    ev_agent = Agents(eval_env_agent, critic)\n",
        "    # Get an agent that is executed on a complete workspace\n",
        "    train_agent = TemporalAgent(tr_agent)\n",
        "    eval_agent = TemporalAgent(ev_agent)\n",
        "    \n",
        "    train_agent.seed(cfg.algorithm.seed)\n",
        "    return train_agent, eval_agent, q_agent, target_q_agent\n",
        "\n",
        "\n",
        "# Configure the optimizer\n",
        "def setup_optimizers(cfg, q_agent):\n",
        "    optimizer_args = get_arguments(cfg.optimizer)\n",
        "    parameters = q_agent.parameters()\n",
        "    optimizer = get_class(cfg.optimizer)(parameters, **optimizer_args)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def compute_critic_loss(cfg, reward, must_bootstrap, q_values, target_q_values, action):\n",
        "    # Compute temporal difference\n",
        "    max_q = target_q_values[1].max(-1)[0].detach()\n",
        "\n",
        "    target = (\n",
        "        reward[:-1]\n",
        "        + cfg.algorithm.discount_factor * max_q * must_bootstrap.int()\n",
        "    )\n",
        "\n",
        "    vals = q_values.squeeze()\n",
        "    qvals = torch.gather(vals, dim=1, index=action)\n",
        "    qvals = qvals[:-1]\n",
        "\n",
        "    mse = nn.MSELoss()\n",
        "    critic_loss = mse(target, qvals)\n",
        "    return critic_loss"
      ],
      "metadata": {
        "id": "HauPdovyH5fG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN"
      ],
      "metadata": {
        "id": "B85LDE9lhEVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dqn(cfg, reward_logger):\n",
        "    print(\"0\")\n",
        "    # 1)  Build the  logger\n",
        "    logger = Logger(cfg)\n",
        "    best_reward = -10e9\n",
        "    print(\"1\")\n",
        "\n",
        "    # 2) Create the environment agent\n",
        "    train_env_agent, eval_env_agent = get_env_agents(cfg)\n",
        "    print(\"2\")\n",
        "\n",
        "    # 3) Create the DQN-like Agent\n",
        "    train_agent, eval_agent, q_agent, target_q_agent = create_dqn_agent(cfg, train_env_agent, eval_env_agent)\n",
        "    print(\"3.1\")\n",
        "\n",
        "    # Used for training\n",
        "    train_workspace = Workspace()\n",
        "    print(\"3.2\")\n",
        "\n",
        "    # 4) Create the Replay Buffer Agent\n",
        "    rb = ReplayBuffer(max_size=cfg.algorithm.buffer_size)\n",
        "    print(\"4\")\n",
        "\n",
        "    # 5) Create the HER Agent\n",
        "    # TO-DO\n",
        "\n",
        "    # 6) Configure the optimizer\n",
        "    optimizer = setup_optimizers(cfg, q_agent)\n",
        "    nb_steps = 0\n",
        "    tmp_steps = 0\n",
        "    tmp_steps2 = 0\n",
        "    print(\"6\")\n",
        "\n",
        "    # 7) Training\n",
        "    # Train des épisodes        \n",
        "    train_agent(train_workspace, t=0, stop_variable=\"env/done\", stochastic=True)\n",
        "    print(\"7.0.1\")\n",
        "\n",
        "    transition_workspace = train_workspace.get_transitions()\n",
        "    print(\"7.0.2\")\n",
        "\n",
        "    # comptage du nb de step de l'épisode\n",
        "    action = transition_workspace[\"action\"]\n",
        "    nb_steps += action[0].shape[0]\n",
        "    print(\"7.0.3\")\n",
        "\n",
        "    # ajout des transitions au RB\n",
        "    rb.put(transition_workspace)\n",
        "    print(\"7.0.4\")\n",
        "\n",
        "    # 7.1) Loop Replay Buffer\n",
        "    for _ in range(cfg.algorithm.n_updates):\n",
        "        # mélange et création du RB_W\n",
        "        rb_workspace = rb.get_shuffled(cfg.algorithm.batch_size)\n",
        "\n",
        "        # The q agent needs to be executed on the rb_workspace workspace (gradients are removed in workspace).\n",
        "        q_agent(rb_workspace, t=0, n_steps=2, choose_action=False)\n",
        "\n",
        "        q_values, done, truncated, reward, action = rb_workspace[\n",
        "            \"q_values\", \"env/done\", \"env/truncated\", \"env/reward\", \"action\"\n",
        "        ]\n",
        "\n",
        "        # print\n",
        "        #print(\"q_values:\", q_values)\n",
        "        #print(\"done:\", done)\n",
        "        #print(\"truncated:\", truncated)\n",
        "        #print(\"reward:\", reward)\n",
        "        #print(\"action:\", action)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_q_agent(rb_workspace, t=0, n_steps=2, stochastic=True)\n",
        "\n",
        "        target_q_values = rb_workspace[\"q_values\"]\n",
        "        # assert torch.equal(q_values, target_q_values), \"values differ\"\n",
        "\n",
        "        # Determines whether values of the critic should be propagated\n",
        "        # True if the episode reached a time limit or if the task was not done\n",
        "        # See https://colab.research.google.com/drive/1erLbRKvdkdDy0Zn1X_JhC01s1QAt4BBj?usp=sharing\n",
        "        must_bootstrap = torch.logical_or(~done[1], truncated[1])\n",
        "\n",
        "        if rb.size() > cfg.algorithm.learning_starts:\n",
        "            # Compute critic loss\n",
        "            critic_loss = compute_critic_loss(\n",
        "                cfg, reward, must_bootstrap, q_values[0], target_q_values[1], action\n",
        "            )\n",
        "\n",
        "            # Store the loss for tensorboard display\n",
        "            logger.add_log(\"critic_loss\", critic_loss, nb_steps)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            critic_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                q_agent.parameters(), cfg.algorithm.max_grad_norm\n",
        "            )\n",
        "            optimizer.step()\n",
        "    print(\"7.1\")\n",
        "\n",
        "    # 7.2) Maj du Q_target (sous conditions)\n",
        "    if nb_steps - tmp_steps2 > cfg.algorithm.target_critic_update:\n",
        "        tmp_steps2 = nb_steps\n",
        "        target_q_agent.agent = copy.deepcopy(q_agent.agent)\n",
        "        print(\"7.2\")\n",
        "    \n",
        "    # 7.3) Évaluation régulère\n",
        "    if nb_steps - tmp_steps > cfg.algorithm.eval_interval:\n",
        "        tmp_steps = nb_steps\n",
        "        eval_workspace = Workspace()  # Used for evaluation\n",
        "        eval_agent(\n",
        "            eval_workspace, t=0, stop_variable=\"env/done\", choose_action=True\n",
        "        )\n",
        "        rewards = eval_workspace[\"env/cumulated_reward\"][-1]\n",
        "        mean = rewards.mean()\n",
        "        logger.add_log(\"reward\", mean, nb_steps)\n",
        "        print(f\"reward: {mean}\")\n",
        "        reward_logger.add(nb_steps, mean)\n",
        "        \n",
        "        if cfg.save_best and mean > best_reward:\n",
        "            best_reward = mean\n",
        "            directory = \"./dqn_critic/\"\n",
        "            \n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            \n",
        "            filename = directory + \"dqn_\" + str(mean.item()) + \".agt\"\n",
        "            eval_agent.save_model(filename)\n",
        "            \n",
        "            if cfg.plot_agents:\n",
        "                policy = eval_agent.agent.agents[1]\n",
        "                plot_policy(\n",
        "                    policy,\n",
        "                    eval_env_agent,\n",
        "                    \"./dqn_plots/\",\n",
        "                    cfg.gym_env.env_name,\n",
        "                    best_reward,\n",
        "                    stochastic=False,\n",
        "                )\n",
        "                plot_critic(\n",
        "                    policy,\n",
        "                    eval_env_agent,\n",
        "                    \"./dqn_plots/\",\n",
        "                    cfg.gym_env.env_name,\n",
        "                    best_reward,\n",
        "                )\n",
        "        print(\"7.3\")"
      ],
      "metadata": {
        "id": "ntdxI1XDR2CP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAIN"
      ],
      "metadata": {
        "id": "u18OyRDdqMBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_loop(cfg):\n",
        "    chrono = Chrono()\n",
        "    logdir = \"./plot/\"\n",
        "\n",
        "    if not os.path.exists(logdir):\n",
        "        os.makedirs(logdir)\n",
        "\n",
        "    reward_logger = RewardLogger(\n",
        "        logdir + \"dqn_test.steps\", logdir + \"dqn_test.rwd\"\n",
        "    )\n",
        "\n",
        "    for seed in range(cfg.algorithm.nb_seeds):\n",
        "        cfg.algorithm.seed = seed\n",
        "        torch.manual_seed(cfg.algorithm.seed)\n",
        "        run_dqn(cfg, reward_logger)\n",
        "\n",
        "        if seed < cfg.algorithm.nb_seeds - 1:\n",
        "            reward_logger.new_episode()\n",
        "\n",
        "    reward_logger.save()\n",
        "    chrono.stop()\n",
        "    plotter = Plotter(logdir + \"dqn_test.steps\", logdir + \"dqn_test.rwd\")\n",
        "    plotter.plot_reward(\"dqn_test\", cfg.gym_env.env_name)"
      ],
      "metadata": {
        "id": "GSN9tztCZX-7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loop(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "jfewpf6pZgQ2",
        "outputId": "c2c06b33-af90-4839-891b-22760f9fe8a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3.1\n",
            "3.2\n",
            "4\n",
            "6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.0.1\n",
            "7.0.2\n",
            "7.0.3\n",
            "7.0.4\n",
            "7.1\n",
            "7.2\n",
            "reward: 78.0\n",
            "7.3\n",
            "Time : 0s 510ms\n",
            "[16] [[19.70000076]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}