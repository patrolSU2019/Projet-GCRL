{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LZXcFYSBs550",
        "hMJF8ZpbyLt0",
        "1WTM15ZG3QcF",
        "Ndj4MZ4-hARb",
        "B85LDE9lhEVj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installations/Préparations"
      ],
      "metadata": {
        "id": "pVXOYNmls5Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install"
      ],
      "metadata": {
        "id": "LZXcFYSBs550"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMZrJSJHsd0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31735ddc-cedd-4b49-c193-41563d535098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/dist-packages (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata==4.13.0) (3.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/osigaud/bbrl\n",
            "  Cloning https://github.com/osigaud/bbrl to /tmp/pip-req-build-trdkxzoc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/osigaud/bbrl /tmp/pip-req-build-trdkxzoc\n",
            "  Resolved https://github.com/osigaud/bbrl to commit cb2c22b82bfedfb04d8232ba432cdbd798fd797a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/dist-packages (from omegaconf) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf) (6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install importlib-metadata==4.13.0\n",
        "#!pip install setuptools==65.5.0\n",
        "#!pip install git+https://github.com/osigaud/bbrl_gym\n",
        "!pip install git+https://github.com/osigaud/bbrl\n",
        "!pip install omegaconf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "hMJF8ZpbyLt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bbrl.workspace import Workspace\n",
        "from bbrl import get_class, get_arguments, instantiate_class\n",
        "\n",
        "#import bbrl_gym\n",
        "import gym\n",
        "\n",
        "from bbrl.agents.agent import Agent\n",
        "from bbrl.agents import Agents, TemporalAgent, PrintAgent\n",
        "from bbrl.agents.gymb import NoAutoResetGymAgent\n",
        "\n",
        "from bbrl.utils.replay_buffer import ReplayBuffer\n",
        "from bbrl.utils.chrono import Chrono\n",
        "\n",
        "from bbrl.visu.visu_policies import plot_policy\n",
        "from bbrl.visu.visu_critics import plot_critic\n",
        "from bbrl.visu.common import final_show\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "from omegaconf import DictConfig\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib\n",
        "import os\n",
        "import functools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import copy"
      ],
      "metadata": {
        "id": "P5EkdUXfslay"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implémentations depuis bbrl_examples"
      ],
      "metadata": {
        "id": "1WTM15ZG3QcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "    def __init__(self, cfg):\n",
        "        self.logger = instantiate_class(cfg.logger)\n",
        "\n",
        "    def add_log(self, log_string, loss, epoch):\n",
        "        self.logger.add_scalar(log_string, loss.item(), epoch)\n",
        "\n",
        "    # Log losses\n",
        "    def log_losses(self, epoch, critic_loss, entropy_loss, actor_loss):\n",
        "        self.add_log(\"critic_loss\", critic_loss, epoch)\n",
        "        self.add_log(\"entropy_loss\", entropy_loss, epoch)\n",
        "        self.add_log(\"actor_loss\", actor_loss, epoch)\n",
        "\n",
        "    def log_reward_losses(self, rewards, nb_steps):\n",
        "        self.add_log(\"reward/mean\", rewards.mean(), nb_steps)\n",
        "        self.add_log(\"reward/max\", rewards.max(), nb_steps)\n",
        "        self.add_log(\"reward/min\", rewards.min(), nb_steps)\n",
        "        self.add_log(\"reward/median\", rewards.median(), nb_steps)\n",
        "\n",
        "def format_num(num, pos):\n",
        "    # Pos is a required parameter, but it is not used\n",
        "    magnitude = 0\n",
        "    labels = [\"\", \"K\", \"M\", \"G\"]\n",
        "    while abs(num) >= 1e3:\n",
        "        magnitude += 1\n",
        "        num /= 1e3\n",
        "\n",
        "    return f\"{num:.1f}{labels[magnitude]}\"\n",
        "\n",
        "class Plotter:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def plot_reward(\n",
        "        self,\n",
        "        algo_name,\n",
        "        env_name,\n",
        "        mode=\"mean\",\n",
        "        prefix=\"\",\n",
        "        suffix=\".pdf\",\n",
        "        save_fig=True,\n",
        "        save_dir=\"./plots/\",\n",
        "    ):\n",
        "        _, ax = plt.subplots(figsize=(9, 6))\n",
        "        formatter = FuncFormatter(format_num)\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        color = colors[0]\n",
        "\n",
        "        loader = RewardLoader(self.steps_filename, self.rewards_filename)\n",
        "        steps, rewards = loader.load()\n",
        "        print(steps, rewards)\n",
        "        # steps, rewards = equalize_lengths(steps, rewards)\n",
        "\n",
        "        if mode == \"best\":\n",
        "            best = rewards.sum(axis=1).argmax()\n",
        "            mean = rewards[best]\n",
        "        elif mode == \"max\":\n",
        "            mean = np.max(rewards, axis=0)\n",
        "        else:\n",
        "            std = rewards.std(axis=0)\n",
        "            mean = rewards.mean(axis=0)\n",
        "            ax.fill_between(steps, mean + std, mean - std, alpha=0.1, color=color)\n",
        "        ax.plot(steps, mean, lw=2, label=f\"{algo_name}\", color=color)\n",
        "        ax.xaxis.set_major_formatter(formatter)\n",
        "        plt.legend()\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        figure_name = f\"{prefix}{clean_env_name.lower()}_{mode}\"\n",
        "        title = f\"{clean_env_name} ({mode})\"\n",
        "        if suffix:\n",
        "            figure_name += f\"{suffix}\"\n",
        "        final_show(save_fig, True, save_dir, figure_name, \"timesteps\", \"rewards\", title)\n",
        "\n",
        "    def plot_histograms(\n",
        "        self,\n",
        "        rewards,\n",
        "        env_name,\n",
        "        suffix=\"\",\n",
        "        save_dir=\"./plots/\",\n",
        "        plot=True,\n",
        "        save_fig=True,\n",
        "    ):\n",
        "        plt.figure(figsize=(9, 6))\n",
        "\n",
        "        colors = [\"#09b542\", \"#008fd5\", \"#fc4f30\", \"#e5ae38\", \"#e5ae38\", \"#810f7c\"]\n",
        "        # colors = [\"#fc4f30\", \"#008fd5\", \"#e5ae38\"]\n",
        "\n",
        "        n_bars = len(rewards)\n",
        "        x = np.arange(len(list(rewards.values())[0]))\n",
        "        width = 0.75 / n_bars\n",
        "\n",
        "        for i, reward in enumerate(rewards.values()):\n",
        "            plt.bar(x + width * i, np.sort(reward)[::-1], width=width, color=colors[i])\n",
        "\n",
        "        plt.legend(labels=rewards.keys())\n",
        "        plt.xticks([], [])\n",
        "\n",
        "        save_dir += f\"{env_name}/\"\n",
        "\n",
        "        clean_env_name = env_name.split(\"-\")[0]\n",
        "        title = clean_env_name\n",
        "        figure_name = f\"{clean_env_name.lower()}-histograms\"\n",
        "\n",
        "        if suffix:\n",
        "            title += f\" ({suffix})\"\n",
        "            figure_name += f\"{suffix}\"\n",
        "\n",
        "        final_show(save_fig, plot, save_dir, figure_name, \"\", \"rewards\", title)\n",
        "\n",
        "class RewardLogger:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "        self.episode = 0\n",
        "        self.all_rewards = []\n",
        "        self.all_rewards.append([])\n",
        "        self.all_steps = []\n",
        "\n",
        "    def add(self, nb_steps, reward):\n",
        "        if self.episode == 0:\n",
        "            self.all_steps.append(nb_steps)\n",
        "        self.all_rewards[self.episode].append(reward.item())\n",
        "\n",
        "    def new_episode(self):\n",
        "        self.episode += 1\n",
        "        self.all_rewards.append([])\n",
        "\n",
        "    def save(self):\n",
        "        # print(\"reward loader save:\", self.all_steps,  self.all_rewards)\n",
        "        with open(self.steps_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_steps)\n",
        "        with open(self.rewards_filename, \"ab\") as f:\n",
        "            np.save(f, self.all_rewards)\n",
        "\n",
        "class RewardLoader:\n",
        "    def __init__(self, steps_filename, rewards_filename):\n",
        "        self.steps_filename = steps_filename\n",
        "        self.rewards_filename = rewards_filename\n",
        "\n",
        "    def load(self):\n",
        "        with open(self.steps_filename, \"rb\") as f:\n",
        "            steps = np.load(f, allow_pickle=True)\n",
        "        with open(self.rewards_filename, \"rb\") as f:\n",
        "            rewards = np.load(f, allow_pickle=True)\n",
        "        return steps, rewards"
      ],
      "metadata": {
        "id": "Uvi68vi0aE7d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mlp(sizes, activation, output_activation=nn.Identity()):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        act = activation if j < len(sizes) - 2 else output_activation\n",
        "        layers += [nn.Linear(sizes[j], sizes[j + 1]), act]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def build_alt_mlp(sizes, activation):\n",
        "    layers = []\n",
        "    for j in range(len(sizes) - 1):\n",
        "        if j < len(sizes) - 2:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1]), activation]\n",
        "        else:\n",
        "            layers += [nn.Linear(sizes[j], sizes[j + 1])]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "class EGreedyActionSelector(Agent):\n",
        "    def __init__(self, epsilon):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        q_values = self.get((\"q_values\", t))\n",
        "        nb_actions = q_values.size()[1]\n",
        "        size = q_values.size()[0]\n",
        "        is_random = torch.rand(size).lt(self.epsilon).float()\n",
        "        random_action = torch.randint(low=0, high=nb_actions, size=(size,))\n",
        "        max_action = q_values.max(1)[1]\n",
        "        action = is_random * random_action + (1 - is_random) * max_action\n",
        "        action = action.long()\n",
        "        self.set((\"action\", t), action)"
      ],
      "metadata": {
        "id": "qV_L1P7H2ZdY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nouveaux Agents & Wrapper"
      ],
      "metadata": {
        "id": "ppvuEIU13vFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vraiment utile ? Wrapper/env inatégnables dans le run\n",
        "# Non utilisée pour l'instant\n",
        "class CartWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(CartWrapper, self).__init__(env)\n",
        "\n",
        "        # choix arbitraire d'un goal de départ\n",
        "        pos = random.uniform(-2.4, 2.4)\n",
        "        vel = random.uniform(-1e3, 1e3)\n",
        "        angle = random.uniform(-.2095, .2095)\n",
        "        angle_vel = random.uniform(-1e3, 1e3)\n",
        "        # set du paramètre goal de l'environnement\n",
        "        self.goal = (pos, vel, angle, angle_vel)\n",
        "\n",
        "        # distance acceptable autour du but\n",
        "        self.eps = 0.5\n",
        "\n",
        "    def step(self, action):\n",
        "        # effectue un step de l'env CartPole\n",
        "        next_state, _, _, info = self.env.step(action)\n",
        "\n",
        "        # calcul de distance entre next_state et le but\n",
        "        distance = np.linalg.norm(next_state - self.goal)\n",
        "\n",
        "        # récompense et fin si distance inférieure à eps\n",
        "        if distance < self.eps:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return next_state, reward, done, info\n",
        "###############\n",
        "###############\n",
        "\n",
        "\n",
        "class GoalRelabellingAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, t, batch_size=1, desired_goal=None, choice=False, resize=False, **kwargs):\n",
        "        if desired_goal != None:\n",
        "            # modification du but désiré par le but atteind\n",
        "            desired_goal = desired_goal.to(torch.float64)\n",
        "            self.set((\"env/desired_goal\", t), desired_goal)\n",
        "\n",
        "        if choice:\n",
        "            # choix arbitraire d'un goal\n",
        "            pos = random.uniform(-2.4, 2.4)\n",
        "            vel = random.uniform(-1, 1)\n",
        "            angle = random.uniform(-.2095, .2095)\n",
        "            angle_vel = random.uniform(-1, 1)\n",
        "\n",
        "            # choix d'une distance acceptable\n",
        "            epsilon_goal = torch.Tensor([0.5, 0.9, 0.05, 0.9])\n",
        "            epsilon_goal = torch.tile(epsilon_goal, (batch_size, 1))\n",
        "\n",
        "            # set du paramètre goal de l'environnement\n",
        "            goal = np.array([pos, vel, angle, angle_vel])\n",
        "            t_goal = torch.from_numpy(goal)\n",
        "            t_goal = torch.tile(t_goal, (batch_size, 1))\n",
        "\n",
        "            self.set((\"env/epsilon_goal\", 0), epsilon_goal)\n",
        "            self.set((\"env/desired_goal\", 0), t_goal)\n",
        "\n",
        "        if resize:\n",
        "            # copie sur chaque temps le goal et le epsilon\n",
        "            desired_goal = self.get((\"env/desired_goal\", 0))\n",
        "            epsilon_goal = self.get((\"env/epsilon_goal\", 0))\n",
        "\n",
        "            self.set((\"env/desired_goal\", t), desired_goal)\n",
        "            self.set((\"env/epsilon_goal\", t), epsilon_goal)\n",
        "\n",
        "\n",
        "class RewardAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, t, **kwargs):\n",
        "        if t != 0:\n",
        "            # Récupération de variables\n",
        "            ## récupération des buts atteints et désirés à l'instant t\n",
        "            desired_goal = self.get((\"env/desired_goal\", 0)).numpy()\n",
        "            obs = self.get((\"env/env_obs\", t)).numpy()\n",
        "\n",
        "            ## récupération de la distance acceptable à l'objectif\n",
        "            epsilon_goal = self.get((\"env/epsilon_goal\", 0)).numpy()\n",
        "\n",
        "            ## récupération du done (fin de l'épisode pour cause de sortie d'espace)\n",
        "            is_ended = self.get((\"env/done\", t)).numpy()\n",
        "\n",
        "            # Calcul de distance entre next_state et le but\n",
        "            distance = np.sqrt( (desired_goal - obs) ** 2 )\n",
        "\n",
        "            # Récompense et done si distance inférieure à eps\n",
        "            ## done si atteind son but\n",
        "            done = np.all(distance < epsilon_goal, axis=1)\n",
        "            ## récompense si atteins son but\n",
        "            reward = np.where(done, 1., 0.)\n",
        "            ## recalcul done si l'épisode est fini (sortie de l'espace)\n",
        "            done = np.logical_or(done, is_ended)\n",
        "\n",
        "            ## transformation en Tensor\n",
        "            t_reward = torch.from_numpy(reward)\n",
        "            t_reward = t_reward.to(torch.float32)     # transformation pour compatibilité de type\n",
        "            t_done = torch.from_numpy(done)\n",
        "\n",
        "            ## set de la reward et du done\n",
        "            self.set((\"env/reward\", t), t_reward)\n",
        "            self.set((\"env/done\", t), t_done)\n",
        "\n",
        "\n",
        "# En cours\n",
        "class HERAgentFinal(Agent):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, t, rb, **kwargs):\n",
        "        pass\n",
        "\n",
        "\n",
        "class GCDQNAgent(Agent):\n",
        "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
        "        super().__init__()\n",
        "        self.is_q_function = True\n",
        "        self.model = build_alt_mlp(\n",
        "            [state_dim *2] + list(hidden_layers) + [action_dim], activation=nn.ReLU()   # *2 car on ajoute un but de la taille d'un état\n",
        "        )\n",
        "\n",
        "    def forward(self, t, choose_action=True, **kwargs):\n",
        "        # Récupération des valeurs pour input\n",
        "        ## observation sur les environements au temps t\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        ## objectif, répété sur les n environements\n",
        "        goal = self.get((\"env/desired_goal\", 0))\n",
        "\n",
        "        agent_input = torch.cat((obs, goal), dim=1)\n",
        "        agent_input = agent_input.to(torch.float32)     # transformation pour compatibilité de type\n",
        "\n",
        "        # Calcul des Q-valeurs\n",
        "        q_values = self.model(agent_input).squeeze(-1)\n",
        "        self.set((\"q_values\", t), q_values)\n",
        "\n",
        "        if choose_action:\n",
        "            action = q_values.argmax(-1)\n",
        "            self.set((\"action\", t), action)\n",
        "\n",
        "    def predict_action(self, obs, stochastic):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        if stochastic:\n",
        "            probs = torch.softmax(q_values, dim=-1)\n",
        "            action = torch.distributions.Categorical(probs).sample()\n",
        "        else:\n",
        "            action = q_values.argmax(-1)\n",
        "        return action\n",
        "\n",
        "    def predict_value(self, obs, action):\n",
        "        q_values = self.model(obs).squeeze(-1)\n",
        "        return q_values[action[0].int()]"
      ],
      "metadata": {
        "id": "PpPmz_8R97pf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-Up"
      ],
      "metadata": {
        "id": "1v6XjQd9zKmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paramètres"
      ],
      "metadata": {
        "id": "kNMqVXUxg9pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params={\n",
        "  \"save_best\": False,\n",
        "  \"plot_agents\": True,\n",
        "  \n",
        "  \"logger\":{\n",
        "    \"classname\": \"bbrl.utils.logger.TFLogger\",\n",
        "    \"log_dir\": \"./dqn_logs/\",\n",
        "    \"cache_size\": 10000,\n",
        "    \"every_n_seconds\": 1,\n",
        "    \"verbose\": False,    \n",
        "  },\n",
        "\n",
        "  \"algorithm\":{\n",
        "    \"seed\": 30,                      # modifié par la main loop\n",
        "    \"nb_seeds\": 1,                  # nb de seed testées (de 0 à valeur proposée)\n",
        "\n",
        "    \"epsilon\": 0.1,                 # valeur pour epsilon-greedy\n",
        "    \"discount_factor\": 0.99,        # delta\n",
        "    \"gae\": 0.8,                     # ???\n",
        "\n",
        "    \"n_steps\": 64,                  # nb max de step par épisode ?\n",
        "    \"n_envs\": 5,                    # nb d'environnement en simultané\n",
        "    \"n_episodes\": 50,                # nb d'épisodes\n",
        "    \"nb_evals\": 10,                 # nb d'évaluation après train\n",
        "    \"eval_interval\": 10,            # intervalle (steps) entre évaluations ?\n",
        "    \"target_critic_update\": 10,    # intervalle (steps) entre chaque maj de Q_target ?\n",
        "\n",
        "    \"learning_starts\": 1,           # ???\n",
        "\n",
        "    \"n_updates\": 20,                # nb d'update par le Replay Buffer\n",
        "    \"buffer_size\": 1e6,             # taille max du Replay Buffer\n",
        "    \"batch_size\": 50,              # taille du batch Replay Buffer\n",
        "\n",
        "    \"max_grad_norm\": 0.5,           # ???\n",
        "    \"architecture\":{\"hidden_size\": [128, 128]},\n",
        "  },\n",
        "\n",
        "  \"gym_env\":{\n",
        "    \"classname\": \"__main__.make_gym_env\",\n",
        "    \"env_name\": \"CartPole-v1\"\n",
        "  },\n",
        "\n",
        "  \"optimizer\":{\n",
        "    \"classname\": \"torch.optim.Adam\",\n",
        "    \"lr\": 2.3e-3,\n",
        "  }\n",
        "}\n",
        "\n",
        "config = OmegaConf.create(params)"
      ],
      "metadata": {
        "id": "wyiQEOfXzLz7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Ndj4MZ4-hARb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gym_env(env_name):\n",
        "    #env = CartWrapper(gym.make(env_name))\n",
        "    #return env\n",
        "    return gym.make(env_name)\n",
        "\n",
        "\n",
        "def get_env_agents(cfg):\n",
        "    train_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.n_envs,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    # print_agent = PrintAgent()\n",
        "    eval_env_agent = NoAutoResetGymAgent(\n",
        "        get_class(cfg.gym_env),\n",
        "        get_arguments(cfg.gym_env),\n",
        "        cfg.algorithm.nb_evals,\n",
        "        cfg.algorithm.seed,\n",
        "    )\n",
        "    return train_env_agent, eval_env_agent\n",
        "\n",
        "\n",
        "def create_dqn_agent(cfg, train_env_agent, eval_env_agent):\n",
        "    obs_size, act_size = train_env_agent.get_obs_and_actions_sizes()\n",
        "\n",
        "    critic = GCDQNAgent(obs_size, cfg.algorithm.architecture.hidden_size, act_size)\n",
        "    explorer = EGreedyActionSelector(cfg.algorithm.epsilon)\n",
        "    target_critic = copy.deepcopy(critic)\n",
        "\n",
        "    goal_label_agent = TemporalAgent(GoalRelabellingAgent())\n",
        "    reward_agent = RewardAgent()\n",
        "    her_agent = TemporalAgent(HERAgentFinal())\n",
        "\n",
        "    q_agent = TemporalAgent(critic)\n",
        "    target_q_agent = TemporalAgent(target_critic)\n",
        "    \n",
        "    tr_agent = Agents(train_env_agent, critic, explorer, reward_agent)\n",
        "    ev_agent = Agents(eval_env_agent, critic, reward_agent)\n",
        "\n",
        "    # Get an agent that is executed on a complete workspace\n",
        "    train_agent = TemporalAgent(tr_agent)\n",
        "    eval_agent = TemporalAgent(ev_agent)\n",
        "\n",
        "    train_agent.seed(cfg.algorithm.seed)\n",
        "    return train_agent, eval_agent, q_agent, target_q_agent, goal_label_agent, her_agent\n",
        "\n",
        "\n",
        "# Configure the optimizer\n",
        "def setup_optimizers(cfg, q_agent):\n",
        "    optimizer_args = get_arguments(cfg.optimizer)\n",
        "    parameters = q_agent.parameters()\n",
        "    optimizer = get_class(cfg.optimizer)(parameters, **optimizer_args)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def compute_critic_loss(cfg, reward, must_bootstrap, q_values, target_q_values, action):\n",
        "    # Compute temporal difference\n",
        "    max_q = target_q_values[1].max(-1)[0].detach()\n",
        "\n",
        "    target = (\n",
        "        reward[:-1]\n",
        "        + cfg.algorithm.discount_factor * max_q * must_bootstrap.int()\n",
        "    )\n",
        "\n",
        "    vals = q_values.squeeze()\n",
        "    qvals = torch.gather(vals, dim=1, index=action)\n",
        "    qvals = qvals[:-1]\n",
        "\n",
        "    mse = nn.MSELoss()\n",
        "    critic_loss = mse(target, qvals)\n",
        "    return critic_loss"
      ],
      "metadata": {
        "id": "HauPdovyH5fG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Méthode Run DQN"
      ],
      "metadata": {
        "id": "B85LDE9lhEVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dqn(cfg, reward_logger):\n",
        "    # 1)  Build the  logger\n",
        "    logger = Logger(cfg)\n",
        "    best_reward = -10e9\n",
        "\n",
        "    # 2) Create the environment agent\n",
        "    train_env_agent, eval_env_agent = get_env_agents(cfg)\n",
        "\n",
        "    # 3) Create the DQN-like Agent\n",
        "    #train_agent, eval_agent, q_agent, target_q_agent = create_dqn_agent(cfg, train_env_agent, eval_env_agent)\n",
        "    train_agent, eval_agent, q_agent, target_q_agent, goal_label_agent, her_agent = create_dqn_agent(cfg, train_env_agent, eval_env_agent)\n",
        "\n",
        "    # 4) Create the Replay Buffer Agent\n",
        "    rb = ReplayBuffer(max_size=cfg.algorithm.buffer_size)\n",
        "\n",
        "    # 6) Configure the optimizer\n",
        "    optimizer = setup_optimizers(cfg, q_agent)\n",
        "    nb_steps = 0\n",
        "    tmp_steps = 0\n",
        "    tmp_steps2 = 0\n",
        "\n",
        "    # 7) Training\n",
        "    # Train des épisodes\n",
        "    for _ in range(cfg.algorithm.n_episodes):\n",
        "        train_workspace = Workspace()\n",
        "\n",
        "        # tirage d'un but pour l'épisode\n",
        "        goal_label_agent(train_workspace, t=0, batch_size=cfg.algorithm.n_envs, choice=True, n_steps=1)\n",
        "        # train sur le workspace\n",
        "        train_agent(train_workspace, t=0, stop_variable=\"env/done\", stochastic=True)\n",
        "        # resize du batch sur chaque t\n",
        "        goal_label_agent(train_workspace, t=0, resize=True, stop_variable=\"env/done\")\n",
        "\n",
        "        transition_workspace = train_workspace.get_transitions()\n",
        "\n",
        "        # comptage du nb de step de l'épisode\n",
        "        action = transition_workspace[\"action\"]\n",
        "        nb_steps += action[0].shape[0]\n",
        "\n",
        "        # ajout des transitions au RB\n",
        "        rb.put(transition_workspace)\n",
        "\n",
        "        # 7.1) Loop Replay Buffer\n",
        "        for _ in range(cfg.algorithm.n_updates):\n",
        "            #her_agent(transition_workspace, t=0, rb=rb, n_steps=2)\n",
        "\n",
        "            # tirage aléatoire d'un minibatch dans un Workspace\n",
        "            rb_workspace = rb.get_shuffled(cfg.algorithm.batch_size)\n",
        "\n",
        "            # modifie le but atteint\n",
        "            achieved_goal = rb_workspace[\"env/env_obs\"][-1]\n",
        "            goal_label_agent(rb_workspace, t=0, desired_goal=achieved_goal, n_steps=1)\n",
        "\n",
        "            # calcul des Q-values\n",
        "            # The q agent needs to be executed on the rb_workspace workspace (gradients are removed in workspace).\n",
        "            q_agent(rb_workspace, t=0, n_steps=2, choose_action=False)\n",
        "\n",
        "            q_values, done, truncated, reward, action = rb_workspace[\n",
        "                \"q_values\", \"env/done\", \"env/truncated\", \"env/reward\", \"action\"\n",
        "            ]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                target_q_agent(rb_workspace, t=0, n_steps=2, stochastic=True)\n",
        "\n",
        "            target_q_values = rb_workspace[\"q_values\"]\n",
        "            # assert torch.equal(q_values, target_q_values), \"values differ\"\n",
        "\n",
        "            # Determines whether values of the critic should be propagated\n",
        "            # True if the episode reached a time limit or if the task was not done\n",
        "            # See https://colab.research.google.com/drive/1erLbRKvdkdDy0Zn1X_JhC01s1QAt4BBj?usp=sharing\n",
        "            must_bootstrap = torch.logical_or(~done[1], truncated[1])\n",
        "\n",
        "            if rb.size() > cfg.algorithm.learning_starts:\n",
        "                # Compute critic loss\n",
        "                critic_loss = compute_critic_loss(\n",
        "                    cfg, reward, must_bootstrap, q_values[0], target_q_values[1], action\n",
        "                )\n",
        "\n",
        "                # Store the loss for tensorboard display\n",
        "                logger.add_log(\"critic_loss\", critic_loss, nb_steps)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                critic_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    q_agent.parameters(), cfg.algorithm.max_grad_norm\n",
        "                )\n",
        "                optimizer.step()\n",
        "\n",
        "        # 7.2) Maj du Q_target (sous conditions)\n",
        "        if nb_steps - tmp_steps2 > cfg.algorithm.target_critic_update:\n",
        "            tmp_steps2 = nb_steps\n",
        "            target_q_agent.agent = copy.deepcopy(q_agent.agent)\n",
        "        \n",
        "        # 7.3) Évaluation régulère\n",
        "        if nb_steps - tmp_steps > cfg.algorithm.eval_interval:\n",
        "            tmp_steps = nb_steps\n",
        "            eval_workspace = Workspace()  # Used for evaluation\n",
        "            # choix d'un but\n",
        "            goal_label_agent(eval_workspace, t=0, batch_size=cfg.algorithm.nb_evals, choice=True, n_steps=1)\n",
        "            # évaluation\n",
        "            eval_agent(\n",
        "                eval_workspace, t=0, stop_variable=\"env/done\", choose_action=True\n",
        "            )\n",
        "            rewards = eval_workspace[\"env/cumulated_reward\"][-1]\n",
        "            mean = rewards.mean()\n",
        "            logger.add_log(\"reward\", mean, nb_steps)\n",
        "            print(f\"reward: {mean}\")\n",
        "            reward_logger.add(nb_steps, mean)\n",
        "            \n",
        "            if cfg.save_best and mean > best_reward:\n",
        "                best_reward = mean\n",
        "                directory = \"./dqn_critic/\"\n",
        "                \n",
        "                if not os.path.exists(directory):\n",
        "                    os.makedirs(directory)\n",
        "                \n",
        "                filename = directory + \"dqn_\" + str(mean.item()) + \".agt\"\n",
        "                eval_agent.save_model(filename)\n",
        "                \n",
        "                if cfg.plot_agents:\n",
        "                    policy = eval_agent.agent.agents[1]\n",
        "                    plot_policy(\n",
        "                        policy,\n",
        "                        eval_env_agent,\n",
        "                        \"./dqn_plots/\",\n",
        "                        cfg.gym_env.env_name,\n",
        "                        best_reward,\n",
        "                        stochastic=False,\n",
        "                    )\n",
        "                    plot_critic(\n",
        "                        policy,\n",
        "                        eval_env_agent,\n",
        "                        \"./dqn_plots/\",\n",
        "                        cfg.gym_env.env_name,\n",
        "                        best_reward,\n",
        "                    )"
      ],
      "metadata": {
        "id": "Yi388sJMkKU1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "u18OyRDdqMBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_loop(cfg):\n",
        "    chrono = Chrono()\n",
        "    logdir = \"./plot/\"\n",
        "\n",
        "    if not os.path.exists(logdir):\n",
        "        os.makedirs(logdir)\n",
        "\n",
        "    reward_logger = RewardLogger(\n",
        "        logdir + \"dqn.steps\", logdir + \"dqn.rwd\"\n",
        "    )\n",
        "\n",
        "    for seed in range(cfg.algorithm.nb_seeds):\n",
        "        cfg.algorithm.seed = seed\n",
        "        torch.manual_seed(cfg.algorithm.seed)\n",
        "        run_dqn(cfg, reward_logger)\n",
        "\n",
        "        if seed < cfg.algorithm.nb_seeds - 1:\n",
        "            reward_logger.new_episode()\n",
        "\n",
        "    reward_logger.save()\n",
        "    chrono.stop()\n",
        "    plotter = Plotter(logdir + \"dqn.steps\", logdir + \"dqn.rwd\")\n",
        "    plotter.plot_reward(\"dqn\", cfg.gym_env.env_name)"
      ],
      "metadata": {
        "id": "GSN9tztCZX-7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loop(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jfewpf6pZgQ2",
        "outputId": "62d6b1c2-582f-468c-e318-9a0112587d2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.9/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reward: 23.100000381469727\n",
            "reward: 9.300000190734863\n",
            "reward: 9.300000190734863\n",
            "reward: 9.800000190734863\n",
            "reward: 9.5\n",
            "reward: 9.699999809265137\n",
            "reward: 9.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.100000381469727\n",
            "reward: 9.5\n",
            "reward: 9.600000381469727\n",
            "reward: 9.100000381469727\n",
            "reward: 9.300000190734863\n",
            "reward: 9.100000381469727\n",
            "reward: 9.5\n",
            "reward: 9.5\n",
            "reward: 9.199999809265137\n",
            "reward: 9.600000381469727\n",
            "reward: 9.100000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.600000381469727\n",
            "reward: 9.5\n",
            "reward: 9.600000381469727\n",
            "reward: 9.699999809265137\n",
            "reward: 9.100000381469727\n",
            "reward: 9.5\n",
            "reward: 9.199999809265137\n",
            "reward: 9.199999809265137\n",
            "reward: 9.5\n",
            "reward: 9.800000190734863\n",
            "reward: 9.899999618530273\n",
            "reward: 9.300000190734863\n",
            "reward: 9.300000190734863\n",
            "reward: 9.5\n",
            "reward: 9.399999618530273\n",
            "reward: 9.399999618530273\n",
            "reward: 9.0\n",
            "reward: 9.100000381469727\n",
            "reward: 9.300000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 9.300000190734863\n",
            "reward: 9.399999618530273\n",
            "reward: 9.800000190734863\n",
            "reward: 9.300000190734863\n",
            "reward: 8.899999618530273\n",
            "reward: 9.199999809265137\n",
            "reward: 9.300000190734863\n",
            "Time : 5s 752ms\n",
            "[  52  130  179  232  278  330  382  428  478  524  574  628  676  722\n",
            "  769  815  864  881  933  982 1021 1071 1123 1174 1224 1270 1321 1375\n",
            " 1426 1483 1538 1588 1640 1687 1740 1784 1836 1888 1941 1989 2034 2081\n",
            " 2137 2188 2237 2283 2333 2381 2432] [[23.10000038  9.30000019  9.30000019  9.80000019  9.5         9.69999981\n",
            "   9.39999962  9.39999962  9.10000038  9.5         9.60000038  9.10000038\n",
            "   9.30000019  9.10000038  9.5         9.5         9.19999981  9.60000038\n",
            "   9.10000038  9.60000038  9.60000038  9.5         9.60000038  9.69999981\n",
            "   9.10000038  9.5         9.19999981  9.19999981  9.5         9.80000019\n",
            "   9.89999962  9.30000019  9.30000019  9.5         9.39999962  9.39999962\n",
            "   9.          9.10000038  9.30000019  9.39999962  9.80000019  9.39999962\n",
            "   9.30000019  9.39999962  9.80000019  9.30000019  8.89999962  9.19999981\n",
            "   9.30000019]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}